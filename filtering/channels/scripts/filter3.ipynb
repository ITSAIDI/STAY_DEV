{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9c1a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm \n",
    "from colorama import Style,Fore\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import time\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8727f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openJson(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def saveJson(path,data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "       json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "       print(Style.BRIGHT+Fore.GREEN+'\\n json saved'+Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2c29a7",
   "metadata": {},
   "source": [
    "# Short Bio probleme resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "797f4b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1836"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channelsF2 = openJson(\"../jsons/channelsF2.json\")\n",
    "len(channelsF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f475b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plages = {\n",
    "    '0-10': 0,\n",
    "    '10-50': 0,\n",
    "    '50-100': 0,\n",
    "    '>100': 0\n",
    "}\n",
    "\n",
    "for item in channelsF2:\n",
    "    bio = item.get('bio', '').strip()\n",
    "    nb_mots = len(bio.split())\n",
    "    \n",
    "    if nb_mots <= 10:\n",
    "        plages['0-10'] += 1\n",
    "    elif nb_mots <= 50:\n",
    "        plages['10-50'] += 1\n",
    "    elif nb_mots <= 100:\n",
    "        plages['50-100'] += 1\n",
    "    else:\n",
    "        plages['>100'] += 1\n",
    "\n",
    "labels = list(plages.keys())\n",
    "counts = list(plages.values())\n",
    "total = sum(counts)\n",
    "percentages = [count / total * 100 for count in counts]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(labels, counts, color='skyblue')\n",
    "\n",
    "for bar, pct in zip(bars, percentages):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height, f'{pct:.1f}%', \n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.xlabel('Plage de nombre de mots dans le bio')\n",
    "plt.ylabel('Nombre de cha√Ænes')\n",
    "plt.title('Distribution des cha√Ænes selon la longueur du bio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5051f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapetube import get_channel\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "def getContext(channel_id):\n",
    "    api_key = os.getenv(\"YOUTUBE_API_KEY2\")\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    video_ids = []\n",
    "    for video in get_channel(channel_id, limit=3, sort_by='newest', content_type='videos'):\n",
    "        video_ids.append(video['videoId'])\n",
    "\n",
    "    if not video_ids:\n",
    "        return \"No videos found.\"\n",
    "\n",
    "    request = youtube.videos().list(part='snippet', id=','.join(video_ids))\n",
    "    response = request.execute()\n",
    "\n",
    "    combined = \"\"\n",
    "    for item in response['items']:\n",
    "        title = item['snippet'].get('title', 'No title')\n",
    "        description = item['snippet'].get('description', 'No description')\n",
    "        tags = ', '.join(item['snippet'].get('tags', [])) if 'tags' in item['snippet'] else 'No tags'\n",
    "\n",
    "        combined += f\"Title: {title}\\nDescription: {description}\\nTags: {tags}\\n\\n\"\n",
    "\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e94bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0\n",
    "for item in tqdm(channelsF2):\n",
    "    bio = item.get('bio', '').strip()\n",
    "    nb_mots = len(bio.split())\n",
    "    \n",
    "    if nb_mots <= 100 :\n",
    "        context = getContext(item['id_chaine'])\n",
    "        item['context'] = context\n",
    "        \n",
    "    temp+=1\n",
    "    if temp >= 100:\n",
    "        saveJson(\"../jsons/channelsF2.json\",channelsF2)\n",
    "        temp = 0\n",
    "   \n",
    "saveJson(\"../jsons/channelsF2.json\",channelsF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d5611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d50fdc1",
   "metadata": {},
   "source": [
    "# 1.Echantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949facc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "echantillon = random.sample(channelsF2, 200)\n",
    "\n",
    "for item in echantillon:\n",
    "    item['link']=f\"https://www.youtube.com/channel/{item['id_chaine']}\"\n",
    "    item['pertinente']=\"\"\n",
    "    \n",
    "saveJson(\"../jsons/echantillon.json\",echantillon)\n",
    "print(len(echantillon))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c1168",
   "metadata": {},
   "source": [
    "# 2.Manuel Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081a8395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "echantillon = openJson(\"../jsons/echantillon.json\")\n",
    "len(echantillon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa6a0bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non ‚Üí 166 chaines\n",
      "oui ‚Üí 34 chaines\n"
     ]
    }
   ],
   "source": [
    "valeurs = [item.get(\"pertinente\") for item in echantillon]\n",
    "compteur = Counter(valeurs)\n",
    "\n",
    "for valeur, nb in compteur.items():\n",
    "    print(f\"{valeur} ‚Üí {nb} chaines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512537a2",
   "metadata": {},
   "source": [
    "# 3.With LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31960427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297579f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_flash_1 = GoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=os.getenv(\"GOOGLE_API_KEY_1\"))\n",
    "gemini_flash_2 = GoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=os.getenv(\"GOOGLE_API_KEY_2\"))\n",
    "gemini_flash_3 = GoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=os.getenv(\"GOOGLE_API_KEY_3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sysprompt = \"\"\"\n",
    "# La d√©finition d‚Äôautosuffisance\n",
    "\n",
    "L'autosuffisance est la d√©marche visant √† acqu√©rir la capacit√© de subvenir par soi-m√™me √† ses besoins fondamentaux, \n",
    "en premier lieu alimentaires par l'autoconsommation ‚Äì c'est-√†-dire produire, r√©colter et conserver un maximum de sa propre nourriture, \n",
    "souvent en privil√©giant le bio, le local et le saisonnier.\n",
    "\n",
    "L'autosuffisance va au-del√† de la simple autonomie mat√©rielle : elle repr√©sente un engagement volontaire pour √™tre moins d√©pendant du syst√®me √©conomique et social ext√©rieur.  \n",
    "Cela implique des choix concrets comme trouver un lieu propice, le concevoir judicieusement (par exemple en permaculture), changer sa mani√®re de valoriser son temps et de consommer, et former ainsi le fondement d'une vie plus autonome.\n",
    "\n",
    "---\n",
    "\n",
    "# Votre mission\n",
    "\n",
    "- D√©cider si une cha√Æne concerne la th√©matique de l‚Äôautosuffisance en se basant sur un contexte qui est soit :\n",
    "   - **context** = nom de la cha√Æne + bio\n",
    "   - OU  \n",
    "   - **context** = nom de la cha√Æne + bio + titres, descriptions, tags des trois derni√®res vid√©os (pour les cha√Ænes dont le bio est tr√®s court ou vide)\n",
    "\n",
    "- **R√©pondre \"oui\" uniquement pour les cha√Ænes qui abordent directement l‚Äôautosuffisance et l‚Äôautonomie.**\n",
    "   Cela inclut :\n",
    "    Cha√Ænes personnelles montrant leur d√©marche d‚Äôautosuffisance (ex. potager, √©levage, √©nergie, conservation, autonomie alimentaire).  \n",
    "    Cha√Ænes m√©dias explicitement centr√©es sur l‚Äôautosuffisance (interviews, conseils, reportages d√©di√©s √† l‚Äôautosuffisance).\n",
    "    Cha√Ænes qui abordent des concepts tr√®s li√©s √† l‚Äôautosuffisance\n",
    "\n",
    "- La pr√©sence de mots-cl√©s comme autosuffisance, autosuffisant, autonomie, vie autonome, autonomie alimentaire, autonomie √©nerg√©tique est un bon indicateur de la pertinence de la cha√Æne.\n",
    "\n",
    "---\n",
    "\n",
    "# Format attendu\n",
    "\n",
    "La r√©ponse doit √™tre au format JSON :\n",
    "\n",
    "  \"decision\": \"oui\" ou \"non\",\n",
    "  \"justification\": \"Justifiez votre d√©cision avec des arguments clairs, expliquant pourquoi la cha√Æne est ou n‚Äôest pas directement li√©e √† l‚Äôautosuffisance selon les crit√®res ci-dessus.\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "userprompt = \"\"\"\n",
    "Le context ici\n",
    "---\n",
    "{context}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", sysprompt),\n",
    "    (\"user\", userprompt)\n",
    "])\n",
    "\n",
    "chain_1 = prompt | gemini_flash_1\n",
    "chain_2 = prompt | gemini_flash_2\n",
    "chain_3 = prompt | gemini_flash_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d570f8f9",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7c1e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': (\"\\n                              Nom Chaine :\\n                              ---\\n                              L‚Äô√îton‚Äôhome\\n                              \\n                              Bio Chaine :\\n                              ---\\n                              Nous sommes un couple parent de 2 jeunes gar√ßons et avons achet√© √† l‚Äô√©t√© 2020 une GRANDE GRANGE sur un peu plus de 3 hectares de terrain dans le Tarn. Notre objectif: transformer cette grange en HABITATION la plus AUTONOME possible, ce par nos propres moyens, et en faire notre petit paradis. Venez partager notre aventure et suivre ce projet un peu fou ici.\\n\\nLe but de notre cha√Æne: montrer toutes les √©tapes de la TRANSFORMATION de la GRANGE en HABITATION, √©changer sur l‚ÄôAUTONOMIE, partager nos DIY en mati√®re de PRODUITS M√âNAGERS et COSM√âTIQUES, toujours dans une optique d‚ÄôAUTONOMIE.\\n\\nPr√©cision importante: nous ne sommes PAS des professionnels du b√¢timent donc nos vid√©os n'ont pas valeur de tutoriels mais de simples partages d'exp√©rience.\\n\\nN‚Äôh√©sitez pas √† laisser vos commentaires et √† vous abonner √† la cha√Æne. Vous pouvez √©galement nous retrouver sur Facebook et Tipeee. En esp√©rant pouvoir vous inspirer.\\n\\nDes bises,\\n\\nAur√©lie & David \\n                            \",)}\n",
      "```json\n",
      "{\n",
      "  \"decision\": \"oui\",\n",
      "  \"justification\": \"La cha√Æne \\\"L‚Äô√îton‚Äôhome\\\" aborde directement l‚Äôautosuffisance et l‚Äôautonomie. Le bio de la cha√Æne mentionne explicitement l'objectif de transformer une grange en habitation la plus autonome possible, de partager des DIY en mati√®re de produits m√©nagers et cosm√©tiques dans une optique d'autonomie. Les mots-cl√©s \\\"autonomie\\\" et \\\"habitation autonome\\\" sont pr√©sents.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "llmInput = \"\\n                              Nom Chaine :\\n                              ---\\n                              L‚Äô√îton‚Äôhome\\n                              \\n                              Bio Chaine :\\n                              ---\\n                              Nous sommes un couple parent de 2 jeunes gar√ßons et avons achet√© √† l‚Äô√©t√© 2020 une GRANDE GRANGE sur un peu plus de 3 hectares de terrain dans le Tarn. Notre objectif: transformer cette grange en HABITATION la plus AUTONOME possible, ce par nos propres moyens, et en faire notre petit paradis. Venez partager notre aventure et suivre ce projet un peu fou ici.\\n\\nLe but de notre cha√Æne: montrer toutes les √©tapes de la TRANSFORMATION de la GRANGE en HABITATION, √©changer sur l‚ÄôAUTONOMIE, partager nos DIY en mati√®re de PRODUITS M√âNAGERS et COSM√âTIQUES, toujours dans une optique d‚ÄôAUTONOMIE.\\n\\nPr√©cision importante: nous ne sommes PAS des professionnels du b√¢timent donc nos vid√©os n'ont pas valeur de tutoriels mais de simples partages d'exp√©rience.\\n\\nN‚Äôh√©sitez pas √† laisser vos commentaires et √† vous abonner √† la cha√Æne. Vous pouvez √©galement nous retrouver sur Facebook et Tipeee. En esp√©rant pouvoir vous inspirer.\\n\\nDes bises,\\n\\nAur√©lie & David \\n                            \",\n",
    "input = {\"context\":llmInput}\n",
    "print(input)\n",
    "print(chain_1.invoke(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "77e4c83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"decision\": \"oui\",\n",
      "  \"justification\": \"La cha√Æne mentionne explicitement la permaculture et les solutions √©cologiques durables, qui sont des concepts li√©s √† l'autosuffisance. De plus, elle √©voque un mode de vie plus simple et durable, ce qui sugg√®re une d√©marche d'autonomie.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "llmInput = \"\\n                              Nom Chaine :\\n                              ---\\n                              R√©enchantons la Terre\\n                              \\n                              Bio Chaine :\\n                              ---\\n                              üêæüåçüé∂ R√©enchantons la Terre :\\nüåª Explorer, connecter, c√©l√©brer √† travers des vid√©os sur :\\n- La vie en √©covillage et la permaculture.\\n- La communication non violente et les p√©dagogies actives.\\n- Les pratiques somatiques et les solutions √©cologiques durables.\\n‚ú® Partager des paroles positives et engag√©es pour inspirer l‚Äôaction.\\nüåà Oser franchir le pas vers un mode de vie plus simple, durable et joyeux.\\n\\n-----\\nüêæüåçüé∂ Re-Enchanting the Earth:\\nüåª Explore, connect, and celebrate through videos about:\\n- Life in ecovillages and permaculture.\\n- Nonviolent communication and active pedagogies.\\n- Somatic practices and sustainable ecological solutions.\\n‚ú® Sharing positive and committed messages to inspire action.\\nüåà Daring to take the step towards a simpler, sustainable, and joyful way of living.\\n \\n                            \"\n",
    "input = {\"context\":llmInput}\n",
    "print(chain_1.invoke(input)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14257a7d",
   "metadata": {},
   "source": [
    "## Run on the samples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a1897",
   "metadata": {},
   "source": [
    "### prepare the LLM input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d5d29b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1836"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "echantillon = openJson(\"../jsons/echantillon.json\")\n",
    "channelsF2  = openJson(\"../jsons/channelsF2.json\")\n",
    "len(channelsF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7b79ca8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "echantillonPredictions= []\n",
    "\n",
    "for item in echantillon:\n",
    "    llmInput = \"\"\n",
    "    for channel in channelsF2:\n",
    "        if  item['id_chaine']==channel['id_chaine']:\n",
    "            if \"context\" in channel:\n",
    "              llmInput = f\"\"\"\n",
    "                              Nom Chaine :\n",
    "                              ---\n",
    "                              {channel['nom_chaine']}\n",
    "                              \n",
    "                              Bio Chaine :\n",
    "                              ---\n",
    "                              {channel['bio']}\n",
    "                              \n",
    "                              contexte d‚Äôapr√®s les vid√©os :\n",
    "                              ---\n",
    "                              {channel['context']}   \n",
    "                          \"\"\"          \n",
    "            else :\n",
    "                 llmInput = f\"\"\"\n",
    "                              Nom Chaine :\n",
    "                              ---\n",
    "                              {channel['nom_chaine']}\n",
    "                              \n",
    "                              Bio Chaine :\n",
    "                              ---\n",
    "                              {channel['bio']} \n",
    "                            \"\"\"\n",
    "            break\n",
    "    echantillonPredictions.append({\n",
    "      'id_chaine':item['id_chaine'],\n",
    "      'llmInput':llmInput\n",
    "    })      \n",
    "\n",
    "saveJson(\"../jsons/echantillonPredictions.json\",echantillonPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f39cc",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f3b3087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "echantillonPredictions = openJson(\"../jsons/echantillonPredictions.json\")\n",
    "len(echantillonPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "14b5460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanAnswer(answer):\n",
    "    answer = answer.strip(\"`\")   \n",
    "    if answer.startswith(\"json\"):\n",
    "        answer = answer[4:].strip() \n",
    "    return  answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñâ        | 39/200 [00:43<02:41,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep for 50 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [02:18<02:04,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep for 50 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [03:27<02:15,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [03:52<01:20,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep for 50 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [05:26<00:44,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep for 50 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [06:53<00:11,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [07:03<00:01,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep for 50 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [07:54<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "temp = 0\n",
    "\n",
    "for item in tqdm(echantillonPredictions):\n",
    "  \n",
    "    input = {\"context\":item[\"llmInput\"]}\n",
    "    try:\n",
    "        if count1  <= 13:\n",
    "            #print(\"KEY 1\")\n",
    "        \n",
    "            answer = cleanAnswer(chain_1.invoke(input))\n",
    "            answer = json.loads(answer)\n",
    "            #print(video['id_video'],'/n',answer)\n",
    "            item.update(answer)\n",
    "            \n",
    "            count1+=1\n",
    "            temp+=1            \n",
    "            \n",
    "            #print(\"count1 \",count1)  \n",
    "            \n",
    "        if count1  > 13 and count2 <= 13:\n",
    "            #print(\"KEY 2\")\n",
    "            \n",
    "            answer = cleanAnswer(chain_2.invoke(input))\n",
    "            answer = json.loads(answer)\n",
    "            #print(video['id_video'],'/n',answer)\n",
    "            item.update(answer)\n",
    "            \n",
    "            count2+=1\n",
    "            temp+=1\n",
    "            #print(\"count2 \",count2) \n",
    "            \n",
    "        if  count1  > 13 and count2  > 13 and count3 <= 13:\n",
    "            \n",
    "            #print(\"KEY 3\")\n",
    "            \n",
    "            answer = cleanAnswer(chain_3.invoke(input))\n",
    "            answer = json.loads(answer)\n",
    "            #print(video['id_video'],'/n',answer)\n",
    "            item.update(answer)\n",
    "            \n",
    "            count3+=1\n",
    "            temp+=1\n",
    "            #print(\"count3 \",count3) \n",
    "                \n",
    "        if count1 > 13 and count2 > 13 and count3 > 13 :\n",
    "            print(\"sleep for 50 s\")\n",
    "            time.sleep(50)\n",
    "            count1 = 0\n",
    "            count2 = 0\n",
    "            count3 = 0\n",
    "        \n",
    "\n",
    "        if temp >= 100:\n",
    "            saveJson(\"../jsons/echantillonPredictions.json\",echantillonPredictions)\n",
    "            temp=0\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"error {e}\")\n",
    "        \n",
    "saveJson(\"../jsons/echantillonPredictions.json\",echantillonPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aadbda",
   "metadata": {},
   "source": [
    "## Validate the approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2325b958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundTruth = openJson(\"../jsons/echantillon.json\")\n",
    "predictions = openJson(\"../jsons/echantillonPredictions.json\")\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7339e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvaluationMetrics(TP,TN,FP,FN):\n",
    "    \n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    #print(f\"Accuracy : {accuracy:.2%}\")\n",
    "    #print(f\"F1-score : {f1_score:.2%}\")\n",
    "    return round(accuracy,2),round(f1_score,2)\n",
    "\n",
    "def getGround(channelID):\n",
    "    for channel in groundTruth:\n",
    "        if channel['id_chaine']==channelID:\n",
    "            return channel['pertinente']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c2d30a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate():\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN = 0\n",
    "    for pred in predictions:\n",
    "        y_reel = getGround(pred['id_chaine'])\n",
    "        y_pred = pred['decision']\n",
    "        if y_pred == 'oui':\n",
    "            if y_reel=='oui':\n",
    "                TP+=1\n",
    "            else :\n",
    "                FP+=1\n",
    "                #print(pred['id_chaine'])\n",
    "        else:\n",
    "            if y_reel=='non':\n",
    "                TN+=1\n",
    "            else :\n",
    "                #print(pred['id_chaine'])\n",
    "                FN+=1\n",
    "    print(f\"Total FP: {FP}\")\n",
    "    print(f\"Total FN: {FN}\")\n",
    "    print(f\"Total TP: {TP}\")\n",
    "    print(f\"Total TN: {TN}\")    \n",
    "    return getEvaluationMetrics(TP,TN,FP,FN)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FP: 8\n",
      "Total FN: 13\n",
      "Total TP: 21\n",
      "Total TN: 158\n",
      "accuarcy : 0.9\n",
      "f1_score : 0.67\n"
     ]
    }
   ],
   "source": [
    "accuracy,f1_score = validate()\n",
    "print(f\"accuarcy : {accuracy}\")\n",
    "print(f\"f1_score : {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e1e7a",
   "metadata": {},
   "source": [
    "# Apply on all Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac3c1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1836"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channelsF2 = openJson(\"../jsons/channelsF2.json\")\n",
    "len(channelsF2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edf0759",
   "metadata": {},
   "source": [
    "## prepare llmInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dd794dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for channel in channelsF2:\n",
    "    llmInput = \"\"\n",
    "    if \"context\" in channel:\n",
    "        llmInput = f\"\"\"\n",
    "                    Nom Chaine :\n",
    "                    ---\n",
    "                    {channel['nom_chaine']}\n",
    "                    \n",
    "                    Bio Chaine :\n",
    "                    ---\n",
    "                    {channel['bio']}\n",
    "                    \n",
    "                    contexte d‚Äôapr√®s les vid√©os :\n",
    "                    ---\n",
    "                    {channel['context']}   \n",
    "                \"\"\"          \n",
    "    else :\n",
    "        llmInput = f\"\"\"\n",
    "                    Nom Chaine :\n",
    "                    ---\n",
    "                    {channel['nom_chaine']}\n",
    "                    \n",
    "                    Bio Chaine :\n",
    "                    ---\n",
    "                    {channel['bio']} \n",
    "                \"\"\"\n",
    "    channel['llmInput'] = llmInput   \n",
    "    \n",
    "saveJson(\"../jsons/channelsF2.json\",channelsF2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3bc99",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11874943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanAnswer(answer):\n",
    "    answer = answer.strip(\"`\")   \n",
    "    if answer.startswith(\"json\"):\n",
    "        answer = answer[4:].strip() \n",
    "    return  answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba96dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "temp = 0\n",
    "\n",
    "for item in tqdm(channelsF2):\n",
    "  \n",
    "    input = {\"context\":item[\"llmInput\"]}\n",
    "    try:\n",
    "        if count1  <= 13:\n",
    "            #print(\"KEY 1\")\n",
    "        \n",
    "            answer = cleanAnswer(chain_1.invoke(input))\n",
    "            answer = json.loads(answer)\n",
    "            #print(video['id_video'],'/n',answer)\n",
    "            item.update(answer)\n",
    "            \n",
    "            count1+=1\n",
    "            temp+=1            \n",
    "            \n",
    "            #print(\"count1 \",count1)  \n",
    "            \n",
    "        if count1  > 13 and count2 <= 13:\n",
    "            #print(\"KEY 2\")\n",
    "            \n",
    "            answer = cleanAnswer(chain_2.invoke(input))\n",
    "            answer = json.loads(answer)\n",
    "            #print(video['id_video'],'/n',answer)\n",
    "            item.update(answer)\n",
    "            \n",
    "            count2+=1\n",
    "            temp+=1\n",
    "            #print(\"count2 \",count2) \n",
    "            \n",
    "        if  count1  > 13 and count2  > 13 and count3 <= 13:\n",
    "            \n",
    "            #print(\"KEY 3\")\n",
    "            \n",
    "            answer = cleanAnswer(chain_3.invoke(input))\n",
    "            answer = json.loads(answer)\n",
    "            #print(video['id_video'],'/n',answer)\n",
    "            item.update(answer)\n",
    "            \n",
    "            count3+=1\n",
    "            temp+=1\n",
    "            #print(\"count3 \",count3) \n",
    "                \n",
    "        if count1 > 13 and count2 > 13 and count3 > 13 :\n",
    "            print(\"sleep for 50 s\")\n",
    "            time.sleep(50)\n",
    "            count1 = 0\n",
    "            count2 = 0\n",
    "            count3 = 0\n",
    "        \n",
    "\n",
    "        if temp >= 100:\n",
    "            saveJson(\"../jsons/channelsF2.json\",echantillonPredictions)\n",
    "            temp=0\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"error {e}\")\n",
    "        \n",
    "saveJson(\"../jsons/channelsF2.json\",echantillonPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8628121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
