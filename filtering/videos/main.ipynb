{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ef75a4",
   "metadata": {},
   "source": [
    "# Refinements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a81e9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca4701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from colorama import Style,Fore\n",
    "from geopy.geocoders import Nominatim\n",
    "from gliner import GLiNER\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openJson(path):\n",
    "    \n",
    "    # Creates the file if not existing\n",
    "    if not os.path.exists(path):\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump([], file)\n",
    "            \n",
    "    # Open it otherwise\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def saveJson(path,data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "       json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "       #print(Style.BRIGHT+Fore.GREEN+'\\n json saved'+Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cfd47b",
   "metadata": {},
   "source": [
    "## Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e57d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def languageDetection(videosPath,savePath):\n",
    "    videos = openJson(videosPath)\n",
    "        \n",
    "    for video in tqdm(videos,'Language Detection...'):\n",
    "        try:\n",
    "            lg = detect((video['titre_video']+video['description']).lower())\n",
    "            if lg == 'fr':\n",
    "                video['langue'] = 'fr'\n",
    "            else:\n",
    "                video['langue'] = 'autre'\n",
    "        except:\n",
    "            print(Style.BRIGHT+Fore.YELLOW+f\"\\n Detection failed for video : {video['id_video']}\"+Style.RESET_ALL)\n",
    "            \n",
    "    saveJson(savePath,videos)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07473a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "languageDetection('../../collecting/jsons/videos.json','./jsons/videosR1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be52f4",
   "metadata": {},
   "source": [
    "## Add channel location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eef2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def locationAdding(channelsPath,videosPath,savePath):\n",
    "    videosR1 = openJson(videosPath)\n",
    "    channels = openJson(channelsPath)\n",
    "    \n",
    "    ################### Channels Countries dictionary\n",
    "    channels_countries = {}\n",
    "    for channel in channels:\n",
    "        channels_countries[channel['id_chaine']]= channel['localisation']\n",
    "     \n",
    "    ################## Refine the language with the country Code if existent\n",
    "    for video in tqdm(videosR1,'locationAdding...'):\n",
    "        if video['langue'] == 'fr':  \n",
    "            channelId = video['id_chaine']\n",
    "            try:\n",
    "                country = channels_countries[channelId]\n",
    "                if country:\n",
    "                    video['langue']+=f'-{country}'\n",
    "            except:\n",
    "                print(Style.BRIGHT+Fore.YELLOW+f\"\\n probleme while locationAdding video: {video['id_video']}\"+Style.RESET_ALL)\n",
    "                \n",
    "    ################## Save the New json file\n",
    "    saveJson(savePath,videosR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb30965",
   "metadata": {},
   "outputs": [],
   "source": [
    "locationAdding('../../collecting/jsons/channels.json','./jsons/videosR1.json','./jsons/videosR2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b583d27",
   "metadata": {},
   "source": [
    "## Add channel location with detection-heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cbf5a4",
   "metadata": {},
   "source": [
    "- We still have french videos but we are not sure if it's is fr-France, because channel has unknowen location\n",
    "- The idea is trying to detect a channel location to be able to decide about the video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed3edcf",
   "metadata": {},
   "source": [
    "### 1.Seperate Channels with unknown country "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = openJson(\"../../collecting/jsons/channels.json\")\n",
    "len(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae16f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_location_Unknown = []\n",
    "for channel in channels :\n",
    "    if channel['localisation']==\"\":\n",
    "        channels_location_Unknown.append(channel)\n",
    "\n",
    "saveJson(\"./jsons/channels_location_Unknown.json\",channels_location_Unknown)\n",
    "len(channels_location_Unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d201a2",
   "metadata": {},
   "source": [
    "### 2.Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6185375",
   "metadata": {},
   "outputs": [],
   "source": [
    "NER = GLiNER.from_pretrained(\"urchade/gliner_multi-v2.1\")\n",
    "geolocator = Nominatim(user_agent=\"geoapi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"Localisation\",\n",
    "    \"Ville\",\n",
    "    \"Commune\",\n",
    "    \"Pays\",\n",
    "    \"Zone géographique\",\n",
    "    \"Continent\",\n",
    "    \"Région\",\n",
    "    \"Département\",\n",
    "    \"Code postal\",\n",
    "    \"Quartier\",\n",
    "    \"Adresse\",\n",
    "    \"Lieu-dit\",\n",
    "    \"Coordonnées GPS\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"Territoire\",\n",
    "    \"Aire urbaine\",\n",
    "    \"Espace rural\",\n",
    "    \"Zone rurale\",\n",
    "    \"Zone urbaine\",\n",
    "    \"Périmètre géographique\",\n",
    "    \"Localité\",\n",
    "]\n",
    "\n",
    "def getNer(context):\n",
    "    locations = []\n",
    "    results =  NER.predict_entities(context, labels)\n",
    "    if results :\n",
    "        for result in results :\n",
    "            if result['score'] > 0.5 :\n",
    "                locations.append(result['text'])\n",
    "    return locations\n",
    "\n",
    "def getGeocoding(locations):\n",
    "    countries = []\n",
    "    details = {}\n",
    "    try :\n",
    "        for location in locations:\n",
    "            Adresse = geolocator.geocode(location, language='fr', addressdetails=True, timeout=10)  \n",
    "            if Adresse and \"country_code\" in Adresse.raw['address']:\n",
    "                code = Adresse.raw['address']['country_code'].upper()\n",
    "                countries.append(code)\n",
    "                details[location]=code\n",
    "            #time.sleep(1)  # respecter la limite Nominatim     \n",
    "        return countries,details\n",
    "    except:\n",
    "        print(\"Error with GeoCoding\")\n",
    "        time.sleep(1)\n",
    "        return countries,details\n",
    "\n",
    "def countRepetitions(countries):\n",
    "    counts = Counter()\n",
    "    for country in countries:  \n",
    "        counts[country] +=1\n",
    "    return counts \n",
    "\n",
    "def getVidoesdata(channelId,videos):\n",
    "    context = ''\n",
    "    for video in videos:\n",
    "        if video['id_chaine']==channelId:\n",
    "            context += video['titre_video']+'\\n'\n",
    "            context += video['description']+'\\n'\n",
    "    return context\n",
    "\n",
    "def findCountry(locations):\n",
    "    countries,details = getGeocoding(locations)\n",
    "    #print(\"countries \",countries)\n",
    "    if len(countries)>0:\n",
    "        if len(countries) == 1:\n",
    "            return countries[0],details\n",
    "        else :\n",
    "            counts = countRepetitions(countries)\n",
    "            return counts.most_common(1)[0][0],details\n",
    "    return '',details\n",
    "\n",
    "def RefineChannel(channel,videos):\n",
    "\n",
    "    locationsChannel_1 = getNer(channel['nom_chaine']+'\\n'+channel['bio'])\n",
    "    #print(\"locationsChannel_1\",locationsChannel_1)\n",
    "\n",
    "    if len(locationsChannel_1)>0:\n",
    "        channelLocation,details = findCountry(locationsChannel_1)  \n",
    "        return channelLocation,details\n",
    "    else :\n",
    "        context = getVidoesdata(channel['id_chaine'],videos)\n",
    "        locationsChannel_2 = getNer(context)\n",
    "        #print(\"locationsChannel_2 \",locationsChannel_2)\n",
    "        if len(locationsChannel_2)>0:\n",
    "\n",
    "            channelLocation,details = findCountry(locationsChannel_2) \n",
    "            return channelLocation,details\n",
    "        else:\n",
    "            return '',{}\n",
    "   \n",
    "def RefineAllChannels(videosPath,channelsUnKPath):\n",
    "\n",
    "    channels_location_Unknown = openJson(channelsUnKPath)\n",
    "    videos = openJson(videosPath)\n",
    "    temp = 0\n",
    "    for channel in tqdm(channels_location_Unknown,\"Channels-Locations Refining...\"):\n",
    "        start = time.time()\n",
    "        channelLocation,details = RefineChannel(channel,videos)\n",
    "        end = time.time()\n",
    "        channel['localisation']=channelLocation\n",
    "        channel['localisation_details']= details\n",
    "        channel['localisationTime(s)'] = end-start\n",
    "       \n",
    "        temp+=1\n",
    "        \n",
    "        # Itermediate Saving (For safety in case the code crashs we don't start over) \n",
    "        \n",
    "        if temp >= 100:\n",
    "            saveJson(channelsUnKPath,channels_location_Unknown)\n",
    "            temp = 0\n",
    "\n",
    "    saveJson(channelsUnKPath,channels_location_Unknown)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4df755",
   "metadata": {},
   "source": [
    "### 3.Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b966b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "RefineAllChannels(\"../../collecting/jsons/videos.json\",\"./jsons/channels_location_Unknown.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b9912a",
   "metadata": {},
   "source": [
    "### 4.Refine the videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab869fde",
   "metadata": {},
   "source": [
    "#### Create channelsR1.json\n",
    "\n",
    "To insert the New locations on the original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a2679",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = openJson(\"../../collecting/jsons/channels.json\")\n",
    "channels_location_Unknown = openJson(\"./jsons/channels_location_Unknown.json\")\n",
    "print(len(channels))\n",
    "print(len(channels_location_Unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24512967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnLocation(channelId):\n",
    "    for channel in channels_location_Unknown:\n",
    "        if channel['id_chaine']==channelId:\n",
    "            return channel['localisation']\n",
    "        \n",
    "for channel in tqdm(channels):\n",
    "    if channel['localisation'] == \"\":\n",
    "        channel['localisation']  = returnLocation(channel['id_chaine'])\n",
    "\n",
    "saveJson(\"./jsons/channelsR1.json\",channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "channelsR1 = openJson(\"./jsons/channelsR1.json\")\n",
    "len(channelsR1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192dfef",
   "metadata": {},
   "source": [
    "#### Create videosR3.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locationAdding('./jsons/channelsR1.json','./jsons/videosR1.json','./jsons/videosR3.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c8702",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "videosR3 = openJson(\"./jsons/videosR3.json\")\n",
    "len(videosR3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe563bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "langue_counter = Counter(video['langue'] for video in videosR3)\n",
    "print(\"Unique values for the language field with occurrences :\")\n",
    "for langue, count in sorted(langue_counter.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"- {langue} : {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247048d4",
   "metadata": {},
   "source": [
    "# Filter by Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videosR3 = openJson(\"./jsons/videosR3.json\")\n",
    "len(videosR3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cee307",
   "metadata": {},
   "outputs": [],
   "source": [
    "videosF1 = []\n",
    "for video in videosR3:\n",
    "    if video['langue']== 'fr-FR':\n",
    "        videosF1.append(video)\n",
    "saveJson(\"./jsons/videosF1.json\",videosF1)\n",
    "len(videosF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d279e2d8",
   "metadata": {},
   "source": [
    "# Filter TV Channels Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf49fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of TV Channels\n",
    "\n",
    "chainesTv = [\n",
    "    \"France 2\", \"France 3\", \"France 4\",\"France 5\",\"Franceinfo\",\n",
    "    \"BFMTV\", \"C8\", \"CStar\", \"Gulli\", \"Cnews\",\n",
    "    \"Canal+\", \"Planète+\", \"LCI\", \"Paris première\",\n",
    "    \"6ter\", \"Arte\", \"M6\", \"W9\",\n",
    "    \"TFX\", \"TMC\", \"NRJ12\", \"TF1\",\"La Chaîne parlementaire\",\n",
    "    \"Chérie 25\", \"RMC\"\n",
    "]\n",
    "chainesTv = [nomTV.lower().replace(\" \", \"\") for nomTV in chainesTv]\n",
    "\n",
    "print(len(chainesTv))\n",
    "print(chainesTv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986af8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "videosF1 = openJson(\"./jsons/videosF1.json\")\n",
    "channels = openJson(\"../../collecting/jsons/channels.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChannelName(channelId):\n",
    "    for channel in channels:\n",
    "        if channel['id_chaine']==channelId:\n",
    "            return channel['nom_chaine'].lower().replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21050a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chainesTVCounter = Counter() # To Count How mutch videos shared by each TV Channel\n",
    "videosChainesTV = []\n",
    "for video in videosF1:\n",
    "    channelName = getChannelName(video['id_chaine'])\n",
    "    for name in chainesTv:\n",
    "        if name in channelName:  \n",
    "            #print(name,' ',channelName,' ',video['id_video'])\n",
    "            chainesTVCounter[name]+=1\n",
    "            videosChainesTV.append(video['id_video'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f460ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "chainesTVCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e79864",
   "metadata": {},
   "outputs": [],
   "source": [
    "videosF2 = []\n",
    "for video in videosF1:\n",
    "    if video['id_video'] not in videosChainesTV:\n",
    "        videosF2.append(video)\n",
    "saveJson(\"./jsons/videosF2.json\",videosF2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42afac00",
   "metadata": {},
   "source": [
    "# Filter by Relevance index\n",
    "\n",
    "- *R.I* = llmScore × α + numQueries × (1-α)\n",
    "- *llmScore* : is a scoring from 1 to 10 (float value) given by a prompted LLM (Gemini in this case).\n",
    "- *numQueries* : is the number of search queries that returned the video in the collecting phase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b2e86e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28efa3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45f2be5",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_flash = GoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    google_api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9856508",
   "metadata": {},
   "outputs": [],
   "source": [
    "sysprompt = \"\"\"\n",
    "# La définition d’autosuffisance\n",
    "---\n",
    "\n",
    "L'autosuffisance est la démarche visant à acquérir la capacité de subvenir par soi-même à ses besoins fondamentaux, \n",
    "en premier lieu alimentaires par l'autoconsommation – c'est-à-dire produire, récolter et conserver un maximum de sa propre nourriture, \n",
    "souvent en privilégiant le bio, le local et le saisonnier. \n",
    "\n",
    "L'autosuffisance Plus qu'une simple recherche d'autonomie matérielle, elle représente un engagement pour être moins dépendant du système économique et social extérieur, impliquant des choix concrets comme trouver un lieu propice et le concevoir judicieusement (par exemple en permaculture), \n",
    "ainsi qu'un changement dans la manière de valoriser son temps et de consommer, formant ainsi le fondement d'une vie plus autonome.\n",
    "\n",
    "---\n",
    "\n",
    "# Votre mission\n",
    "---\n",
    "\n",
    "- Décider si une vidéo concerne la thématique de l'autosuffisance en se basant sur ses métadonnées (titre, description, tags).  \n",
    "\n",
    "- Attribuer un score (float) de 1 à 10 pour évaluer la pertinence de la vidéo par rapport à la thématique de l'autosuffisance.\n",
    "\n",
    "# Les vidéos pertinentes (Répondre par oui)\n",
    "---\n",
    "\n",
    "- Les vlogs, les interviews et les vidéos de partage d'expériences en lien avec l'autosuffisance sont intéressants.  \n",
    "- Les tutoriels et les vidéos de conseils sont également pertinents.  \n",
    "- Les vidéos présentant une technique liée à l'autosuffisance ou y contribuant sont utiles.  \n",
    "- Donner un score plus élevé pour les vidéos qui mentionnent explicitement des mots-clés liés à cette thématique.\n",
    "\n",
    "# Les vidéos non pertinentes (Répondre par non)\n",
    "---\n",
    "\n",
    "- **Les vidéos provenant d'une chaîne TV ou radio** doivent être exclues, même si elles parlent d'autosuffisance.  \n",
    "- **Les vidéos concernant un emplacement hors de la France** \n",
    "- **Les vidéos d'entreprises commercialisant des produits ou des vidéos publicitaires.**  \n",
    "- **Les vidéos hors sujet**, telles que les webinaires, webconférences, ou présentations commerciales.\n",
    "\n",
    "---\n",
    "\n",
    "# Votre réponse  \n",
    "--- \n",
    "\n",
    "- La réponse doit être au format JSON :  \n",
    "\n",
    "    \"decision\": \"oui ou non\",\n",
    "    \"justification\": \"Justifiez votre décision avec des arguments\",\n",
    "    \"score\": Votre évaluation en format décimal pour que ce soit plus précis.\n",
    "\"\"\"\n",
    "\n",
    "userprompt = \"\"\"\n",
    "Titre\n",
    "---\n",
    "{titre}\n",
    "Description\n",
    "---\n",
    "{description}\n",
    "tags\n",
    "---\n",
    "{tags}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", sysprompt),\n",
    "    (\"user\", userprompt)\n",
    "])\n",
    "\n",
    "def cleanAnswer(answer):\n",
    "    answer = answer.strip(\"`\")   \n",
    "    if answer.startswith(\"json\"):\n",
    "        answer = answer[4:].strip() \n",
    "    return  answer\n",
    "\n",
    "chain = prompt | gemini_flash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed95cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "input = {\"titre\":\"Reportage : Culture hors sol, solution pour l'autosuffisance alimentaire\",\n",
    "         \"description\":\"Face aux défis croissants des produits maraîchers de qualités, certaines familles  font recours à ces pratiques pour assurer une alimentation saine et durable.  \\n#information  #culture  #reportage\",\n",
    "         \"tags\":', '.join( [\n",
    "     \n",
    "    ])}\n",
    "print(input)\n",
    "print(cleanAnswer(chain.invoke(input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf245632",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed3f632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRI(videosPath,savePath,alpha):\n",
    "    videos = openJson(videosPath)\n",
    "    saveCount = 0\n",
    "    apiCount = 0 # in the free vesion we have only 15 requests/min\n",
    "    \n",
    "    for video in tqdm(videos,'Calculating R.I...'):\n",
    "        input = {\"titre\":video['titre_video'],\n",
    "            \"description\":video['description'],\n",
    "            \"tags\":', '.join(video['tags']),}\n",
    "        try:\n",
    "            \n",
    "            LLMResponse = cleanAnswer(chain.invoke(input))\n",
    "            #print('LLMResponse ',LLMResponse)\n",
    "            LLMjson = json.loads(LLMResponse)\n",
    "            numQueries  = len(video['requete'])    \n",
    "            RI = alpha*LLMjson['score']+(1-alpha)*numQueries\n",
    "            \n",
    "            video.update(LLMjson)\n",
    "            video['RI']=RI\n",
    "            \n",
    "            apiCount +=1\n",
    "            \n",
    "            # API Delay to avoid blocking by google\n",
    "            if apiCount == 13:\n",
    "                print(\"sleep for 1 min\")\n",
    "                time.sleep(60)\n",
    "                apiCount =0\n",
    "            \n",
    "            # Safety Saving\n",
    "            saveCount +=1\n",
    "            if saveCount == 100:\n",
    "                saveJson(savePath,videos)\n",
    "                saveCount =0\n",
    "                \n",
    "        except Exception as e:\n",
    "            video['RI'] = -1\n",
    "            print(\"Error occurred:\", e)\n",
    "     \n",
    "    saveJson(savePath,videos)\n",
    "            \n",
    "def filterByRI(videosPath,savePath,threshold):\n",
    "    videos = openJson(videosPath)\n",
    "    videosF3 = []\n",
    "    for video in tqdm(videos,'Filtering by R.I...'):\n",
    "        if video['RI'] > threshold:\n",
    "            videosF3.append(video)\n",
    "            \n",
    "    saveJson(savePath,videosF3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b7d8c",
   "metadata": {},
   "source": [
    "## Run on ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe273ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R.I...:  43%|████▎     | 12/28 [00:14<00:19,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep for 1 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R.I...:  89%|████████▉ | 25/28 [01:27<00:03,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep for 1 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R.I...: 100%|██████████| 28/28 [02:30<00:00,  5.37s/it]\n"
     ]
    }
   ],
   "source": [
    "calculateRI('./jsons/videosF2.json','./jsons/videosR4.json',0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering by R.I...: 100%|██████████| 28/28 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "filterByRI('./jsons/videosR4.json','./jsons/videosF3.json',4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agrotube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
