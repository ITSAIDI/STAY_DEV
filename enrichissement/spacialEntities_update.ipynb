{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354aa2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from tqdm import tqdm \n",
    "from colorama import Style,Fore\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49a84459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openJson(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def saveJson(path,data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "       json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "       print(Style.BRIGHT+Fore.GREEN+'\\n json saved'+Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86223f53",
   "metadata": {},
   "source": [
    "# Update DB with the new tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fdfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(\n",
    "    dbname=\"youtubestay\",\n",
    "    user=\"postgres\",\n",
    "    password=os.getenv(\"POSTGRE_PASSWORD\"),\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE entites_spatiales (\n",
    "        id_entite_spatiale TEXT PRIMARY KEY,\n",
    "        label TEXT NOT NULL,\n",
    "        latitude FLOAT NOT NULL,\n",
    "        longitude FLOAT NOT NULL \n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE entites_spatiales_videos (\n",
    "        id_entite_spatiale TEXT REFERENCES entites_spatiales(id_entite_spatiale) ON DELETE CASCADE,\n",
    "        id_video TEXT REFERENCES videos(id_video) ON DELETE CASCADE,\n",
    "        PRIMARY KEY (id_video, id_entite_spatiale)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE entites_spatiales_chaines (\n",
    "        id_entite_spatiale TEXT REFERENCES entites_spatiales(id_entite_spatiale) ON DELETE CASCADE,\n",
    "        id_chaine TEXT REFERENCES chaines(id_chaine) ON DELETE CASCADE,\n",
    "        PRIMARY KEY (id_chaine, id_entite_spatiale)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2bf7d5",
   "metadata": {},
   "source": [
    "# Fill the spacial_entities_videos table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05e82b7",
   "metadata": {},
   "source": [
    "## Prepare json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ca2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(\n",
    "    dbname=\"youtubestay\",\n",
    "    user=\"postgres\",\n",
    "    password=os.getenv(\"POSTGRE_PASSWORD\"),\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "SELECT v.id_video,v.titre,v.description,v.tags \n",
    "FROM videos v JOIN chaines c ON v.id_chaine = c.id_chaine\n",
    "WHERE c.pertinente = true;\n",
    "\"\"\"\n",
    ")\n",
    "rows = cur.fetchall()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "videos = []\n",
    "for row in rows:\n",
    "    id_video, titre, description, tags = row\n",
    "    videos.append({\n",
    "        \"id_video\": id_video,\n",
    "        \"titre\": titre,\n",
    "        \"description\": description,\n",
    "        \"tags\": tags\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ab7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f74e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveJson('./jsons/videosForSpacialAnalysis.json',videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d52263",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc29a0f",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dccb0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_template = \"\"\"\n",
    "Tu es un extracteur d'entités géographiques.\n",
    "\n",
    "À partir d’un texte donné, identifie toutes les localisations situées en France.\n",
    "\n",
    "Ignore :\n",
    "- les noms de pays (ex : \"France\"),\n",
    "- les noms de personnes,\n",
    "- les noms de chaînes YouTube, plateformes ou services numériques (ex : YouTube, Tipeee),\n",
    "- les noms imaginaires, poétiques ou fictifs.\n",
    "\n",
    "Retourne uniquement une **liste Python**, en **minuscules**, **sans doublons**, contenant **uniquement** des noms de lieux **réels** situés en **France**.\n",
    "\n",
    "Aucune explication. **Donne uniquement le résultat au format requis.**\n",
    "\"\"\"\n",
    "\n",
    "user_template = \"Contexte : {contexte}\"\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(system_template)\n",
    "user_message = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, user_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02501013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "llm_nvidia = ChatNVIDIA(\n",
    "  model=\"meta/llama-3.1-8b-instruct\",\n",
    "  api_key=os.getenv('NVIDIA_API_KEY'), \n",
    "  temperature=0,\n",
    "  top_p=0.7,\n",
    ")\n",
    "\n",
    "chain_nvidia =  chat_prompt | llm_nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08dfb644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm_ollama = ChatOllama(model=\"mistral-nemo:12b\")\n",
    "chain_ollama =  chat_prompt | llm_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed3a1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bae7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedVideosNew = openJson(\"./jsons/updatedVideosNew.json\")\n",
    "len(updatedVideosNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dae3c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "startFrom = len(updatedVideosNew)\n",
    "\n",
    "def getContext(title,description,tags):\n",
    "    videoContext = ''\n",
    "    videoContext+=title\n",
    "    videoContext+= '\\n'+description\n",
    "    if tags:\n",
    "        videoContext += '\\n'+ ', '.join(tags)\n",
    "    return videoContext\n",
    "\n",
    "def getLLMresponse_google(context,suffix):\n",
    "    llm_gemini = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite-preview-06-17\", temperature=0,api_key=os.getenv('GEMINI_API_KEY_'+suffix))\n",
    "    chain_gemini =  chat_prompt | llm_gemini\n",
    "    response = chain_gemini.invoke({'contexte':context})\n",
    "    #print('response ',response)\n",
    "    return response\n",
    "  \n",
    "def getLLMresponse_nvidia(context):\n",
    "    response = chain_nvidia.invoke({'contexte':context})\n",
    "    #print('response ',response)\n",
    "    return response\n",
    "\n",
    "def getLLMresponse_ollama(context):\n",
    "    response = chain_ollama.invoke({'contexte':context})\n",
    "    #print('response ',response)\n",
    "    return response\n",
    "\n",
    "def getSpacialEntities_google(context,suffix):\n",
    "    response = getLLMresponse_google(context,suffix)\n",
    "    \n",
    "    try:\n",
    "        entities = eval(response.content.strip())\n",
    "        if isinstance(entities, list):\n",
    "            Entities = []\n",
    "            for e in entities:\n",
    "                e_cleaned = e.lower().strip()\n",
    "                Entities.append(e_cleaned)\n",
    "            return Entities\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def getSpacialEntities_nvidia(context):\n",
    "    response = getLLMresponse_nvidia(context)\n",
    "    \n",
    "    try:\n",
    "        entities = eval(response.content.strip())\n",
    "        if isinstance(entities, list):\n",
    "            Entities = []\n",
    "            for e in entities:\n",
    "                e_cleaned = e.lower().strip()\n",
    "                Entities.append(e_cleaned)\n",
    "            return Entities\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def getSpacialEntities_ollama(context):\n",
    "    response = getLLMresponse_ollama(context)\n",
    "    \n",
    "    try:\n",
    "        entities = eval(response.content.strip())\n",
    "        if isinstance(entities, list):\n",
    "            Entities = []\n",
    "            for e in entities:\n",
    "                e_cleaned = e.lower().strip()\n",
    "                Entities.append(e_cleaned)\n",
    "            return Entities\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def getGeocoding(entity):\n",
    "    url = \"https://nominatim.openstreetmap.org/search\"\n",
    "    params = {\n",
    "        \"q\": entity,\n",
    "        \"format\": \"json\",\n",
    "        \"limit\": 1,\n",
    "        \"addressdetails\": 1\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"geo-entity-extractor/1.0\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            lat = float(data[0][\"lat\"])\n",
    "            lon = float(data[0][\"lon\"])\n",
    "            country = data[0].get(\"address\", {}).get(\"country\", \"unknown\")\n",
    "            return {\n",
    "                'lat': lat,\n",
    "                'lon': lon,\n",
    "                'country': country\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur pour l'entité '{entity}': {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def runAll(jsonfile):\n",
    "    videos = openJson(jsonfile)\n",
    "    counter = 0\n",
    "    MyAPIsuffix = ['MONO','NOUR','NOUR2008','TEXTRA','ZEG']\n",
    "    #MyAPIsuffix = ['MONO_1','MONO_2','MONO_3','MONO_4','MONO_5']\n",
    "    index = 0\n",
    "    apiCounter = 0\n",
    "    \n",
    "    updatedVideosNew = openJson(\"./jsons/updatedVideosNew.json\") # We open the old jsonfile so we continue from the video we stopped in.\n",
    "    \n",
    "    for video in tqdm(videos[startFrom:]):\n",
    "        videoContext = getContext(video['titre'],video['description'],video['tags'])\n",
    "        \n",
    "        videoSpacialEntities = getSpacialEntities_google(videoContext,MyAPIsuffix[index])\n",
    "        \n",
    "        time.sleep(2)\n",
    "        #videoSpacialEntities = getSpacialEntities_nvidia(videoContext)\n",
    "        #videoSpacialEntities = getSpacialEntities_ollama(videoContext)\n",
    "        \n",
    "        #print(\"videoSpacialEntities  \",videoSpacialEntities)\n",
    "        \n",
    "        if videoSpacialEntities and len(videoSpacialEntities) > 0:\n",
    "            output = []\n",
    "            for ent in videoSpacialEntities:\n",
    "                geocoding = getGeocoding(ent)\n",
    "                if geocoding and geocoding['country']=='France':\n",
    "                    geocoding['ent']=ent\n",
    "                    output.append(geocoding)\n",
    "            if len(output) >0 :\n",
    "                video['output'] = output\n",
    "                \n",
    "        # Updating the new list\n",
    "        updatedVideosNew.append(video)\n",
    "        \n",
    "        # Safe Saving \n",
    "        counter+= 1\n",
    "        if counter == 20:\n",
    "            saveJson(\"./jsons/updatedVideosNew.json\",updatedVideosNew)\n",
    "            counter =0\n",
    "            \n",
    "        # API Switching\n",
    "        \n",
    "        apiCounter +=1\n",
    "        if apiCounter == 13:\n",
    "            index+=1\n",
    "            apiCounter = 0\n",
    "            if index==len(MyAPIsuffix):\n",
    "                print(Style.BRIGHT+Fore.BLUE+'\\n sleep for 60s'+Style.RESET_ALL)\n",
    "                time.sleep(60)\n",
    "                index=0\n",
    "            print(Style.BRIGHT+Fore.YELLOW+f'\\n API KEY switched to {MyAPIsuffix[index]}'+Style.RESET_ALL)\n",
    "            \n",
    "        \"\"\"\n",
    "        apiCounter +=1\n",
    "        if apiCounter == 35:\n",
    "            print(Style.BRIGHT+Fore.BLUE+'\\n sleep for 60s'+Style.RESET_ALL)\n",
    "            time.sleep(60)\n",
    "            apiCounter = 0\n",
    "        \"\"\"\n",
    "        \n",
    "    # Saving \n",
    "    saveJson(\"./jsons/updatedVideosNew.json\",updatedVideosNew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee17be8",
   "metadata": {},
   "source": [
    "### Run on some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72180564",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = openJson('./jsons/test.json')\n",
    "len(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyAPIsuffix = ['MONO_1','MONO_2','MONO_3','MONO_4','MONO_5']\n",
    "index = 0\n",
    "apiCounter = 0\n",
    "\n",
    "for video in tqdm(testData):\n",
    "    output = []\n",
    "    context = getContext(video['titre'],video['description'],video['tags'])\n",
    "    entities = getSpacialEntities_google(context,MyAPIsuffix[index])\n",
    "    #entities = getSpacialEntities_ollama(context)\n",
    "    print('entities :',entities)\n",
    "    if entities:\n",
    "        for ent in entities:\n",
    "            result = {'ent':ent}\n",
    "            geoCode = getGeocoding(ent)\n",
    "            if geoCode:\n",
    "                result.update(geoCode)\n",
    "            output.append(result)\n",
    "            #print('output  :',output)\n",
    "    video['output'] = output\n",
    "            \n",
    "    # API Switching\n",
    "     \n",
    "    apiCounter +=1\n",
    "    if apiCounter == 13:\n",
    "        index+=1\n",
    "        apiCounter = 0\n",
    "        if index==5:\n",
    "            print(Style.BRIGHT+Fore.BLUE+'\\n sleep for 60s'+Style.RESET_ALL)\n",
    "            time.sleep(60)\n",
    "            index=0\n",
    "        print(Style.BRIGHT+Fore.YELLOW+f'\\n API KEY switched to {MyAPIsuffix[index]}'+Style.RESET_ALL)\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveJson('./jsons/testResults.json',testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05730a4c",
   "metadata": {},
   "source": [
    "### Plot in map an Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0e1c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "location_data = {\n",
    "        \"ent\": \"brian\",\n",
    "        \"lat\": 45.5913283,\n",
    "        \"lon\": 12.8142248,\n",
    "      }\n",
    "map_obj = folium.Map(location=[location_data[\"lat\"], location_data[\"lon\"]], zoom_start=13)\n",
    "\n",
    "folium.Marker(\n",
    "    [location_data[\"lat\"], location_data[\"lon\"]],\n",
    "    popup=location_data[\"ent\"],\n",
    "    tooltip=location_data[\"ent\"]\n",
    ").add_to(map_obj)\n",
    "\n",
    "map_obj.save(\"map_janze.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4b93e5",
   "metadata": {},
   "source": [
    "### Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef97f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1274/35283 [1:16:54<35:30:55,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1280/35283 [1:17:18<37:42:27,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1287/35283 [1:17:48<39:04:21,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1299/35283 [1:18:36<33:06:25,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "runAll(\"./jsons/videosForSpacialAnalysis.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89731422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09b1a481",
   "metadata": {},
   "source": [
    "## Old Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d88e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_template = \"\"\"\n",
    "Tu es un extracteur d'entités géographiques françaises.\n",
    "À partir d’un texte donné, identifie uniquement les **villes**, **communes** situés en France.\n",
    "Ne prends **pas** en compte :\n",
    "- les noms de pays (ex: \"France\"),\n",
    "- les noms de personnes,\n",
    "- les noms de chaînes YouTube, de plateformes (ex: YouTube, Tipeee),\n",
    "- les noms imaginaires ou poétiques.\n",
    "\n",
    "Retourne une **liste Python**, en minuscules, sans doublons, contenant uniquement des noms de lieux réels en France.\n",
    "Pas d'explication, donner la reponse en format string.\n",
    "\n",
    "**Les noms extraits doivent être en français**\n",
    "**Pas d'explication juste la liste**\n",
    "\"\"\"\n",
    "\n",
    "user_template = \"Contexte : {contexte}\"\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(system_template)\n",
    "user_message = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, user_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4095710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm_ollama = ChatOllama(model=\"llama3.1:8b\")\n",
    "chain_ollama =  chat_prompt | llm_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "llm_nvidia = ChatNVIDIA(\n",
    "  model=\"meta/llama-3.1-8b-instruct\",\n",
    "  api_key=os.getenv('NVIDIA_API_KEY'), \n",
    "  temperature=0,\n",
    "  top_p=0.7,\n",
    ")\n",
    "\n",
    "chain_nvidia =  chat_prompt | llm_nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe59faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66227fb6",
   "metadata": {},
   "source": [
    "{\n",
    "    id_video = '',\n",
    "    titre : '',\n",
    "    description:'',\n",
    "    tags:''\n",
    "    +\n",
    "    output : [\n",
    "            {\n",
    "            ent : Ent1\n",
    "            lat :\n",
    "            lon : },\n",
    "            {\n",
    "            ent : Ent2\n",
    "            lat :\n",
    "            lon : },\n",
    "        ...\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedVideos = openJson(\"./jsons/updatedVideos.json\")\n",
    "len(updatedVideos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52295510",
   "metadata": {},
   "outputs": [],
   "source": [
    "startFrom = len(updatedVideos)\n",
    "\n",
    "def getContext(title,description,tags):\n",
    "    videoContext = ''\n",
    "    videoContext+=title\n",
    "    videoContext+= '\\n'+description\n",
    "    if tags:\n",
    "        videoContext += '\\n'+ ', '.join(tags)\n",
    "    return videoContext\n",
    "\n",
    "def getEntityVerification(entity,csvfile,column):\n",
    "    with open(csvfile, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if row[column].strip().lower() == entity:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def getLLMresponse_google(context,suffix):\n",
    "    llm_gemini = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite-preview-06-17\", temperature=0,api_key=os.getenv('GEMINI_API_KEY_'+suffix))\n",
    "    chain_gemini =  chat_prompt | llm_gemini\n",
    "    response = chain_gemini.invoke({'contexte':context})\n",
    "    #print('response ',response)\n",
    "    return response\n",
    "   \n",
    "def getLLMresponse_nvidia(context):\n",
    "    response = chain_nvidia.invoke({'contexte':context})\n",
    "    #print('response ',response)\n",
    "    return response\n",
    "  \n",
    "def getSpacialEntities_google(context,suffix):\n",
    "    response = getLLMresponse_google(context,suffix)\n",
    "    \n",
    "    try:\n",
    "        entities = eval(response.content.strip())\n",
    "        if isinstance(entities, list):\n",
    "            Entities = []\n",
    "            for e in entities:\n",
    "                e_cleaned = e.lower().strip()\n",
    "                if getEntityVerification(e_cleaned,'./csvs/v_commune_2025.csv','NCCENR'):\n",
    "                    Entities.append(e_cleaned)\n",
    "            return Entities\n",
    "    except:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def getSpacialEntities_nvidia(context):\n",
    "    response = getLLMresponse_nvidia(context)\n",
    "    \n",
    "    try:\n",
    "        entities = eval(response.content.strip())\n",
    "        if isinstance(entities, list):\n",
    "            Entities = []\n",
    "            for e in entities:\n",
    "                e_cleaned = e.lower().strip()\n",
    "                if getEntityVerification(e_cleaned,'./csvs/v_commune_2025.csv','NCCENR'):\n",
    "                    Entities.append(e_cleaned)\n",
    "            return Entities\n",
    "    except:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def getGeocoding(entity):\n",
    "    url = \"https://nominatim.openstreetmap.org/search\"\n",
    "    params = {\n",
    "        \"q\": entity + \", France\",\n",
    "        \"format\": \"json\",\n",
    "        \"limit\": 1\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"geo-entity-extractor/1.0\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            lat = float(data[0][\"lat\"])\n",
    "            lon = float(data[0][\"lon\"])\n",
    "            return {'lat':lat,\n",
    "                    'lon':lon}\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur pour l'entité '{entity}': {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def runAll(jsonfile):\n",
    "    videos = openJson(jsonfile)\n",
    "    counter = 0\n",
    "    MyAPIsuffix = ['MONO','NOUR','NOUR2008','TEXTRA','ZEG']\n",
    "    index = 0\n",
    "    apiCounter = 0\n",
    "    \n",
    "    updatedVideos = openJson(\"./jsons/updatedVideos.json\") # We open the old jsonfile so we continue from the video we stopped in.\n",
    "    \n",
    "    for video in tqdm(videos[startFrom:]):\n",
    "        videoContext = getContext(video['titre'],video['description'],video['tags'])\n",
    "        \n",
    "        videoSpacialEntities = getSpacialEntities_google(videoContext,MyAPIsuffix[index])\n",
    "        \n",
    "        #videoSpacialEntities = getSpacialEntities_nvidia(videoContext)\n",
    "        \n",
    "        #print(\"videoSpacialEntities  \",videoSpacialEntities)\n",
    "        if len(videoSpacialEntities) > 0:\n",
    "            output = []\n",
    "            for ent in videoSpacialEntities:\n",
    "                geocoding = getGeocoding(ent)\n",
    "                if geocoding :\n",
    "                    geocoding['ent']=ent\n",
    "                    output.append(geocoding)\n",
    "            if len(output) >0 :\n",
    "                video['output'] = output\n",
    "                \n",
    "        # Updating the new list\n",
    "        updatedVideos.append(video)\n",
    "        \n",
    "        # Safe Saving \n",
    "        counter+= 1\n",
    "        if counter == 100:\n",
    "            saveJson(\"./jsons/updatedVideos.json\",updatedVideos)\n",
    "            counter =0\n",
    "            \n",
    "        # API Switching\n",
    "        \n",
    "        apiCounter +=1\n",
    "        if apiCounter == 13:\n",
    "            index+=1\n",
    "            apiCounter = 0\n",
    "            if index==5:\n",
    "                print(Style.BRIGHT+Fore.BLUE+'\\n sleep for 60s'+Style.RESET_ALL)\n",
    "                time.sleep(60)\n",
    "                index=0\n",
    "            print(Style.BRIGHT+Fore.YELLOW+f'\\n API KEY switched to {MyAPIsuffix[index]}'+Style.RESET_ALL)\n",
    "            \n",
    "        \"\"\"\n",
    "        apiCounter +=1\n",
    "        if apiCounter == 35:\n",
    "            print(Style.BRIGHT+Fore.BLUE+'\\n sleep for 60s'+Style.RESET_ALL)\n",
    "            time.sleep(60)\n",
    "            apiCounter = 0\n",
    "        \"\"\"\n",
    "        \n",
    "    # Saving \n",
    "    saveJson(\"./jsons/updatedVideos.json\",updatedVideos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb943e",
   "metadata": {},
   "source": [
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1382096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Ils vivent dans une maison bâtie avec des déchets\"\n",
    "description = \"\\\"Elle nous protège, elle nous nourrit, elle nous réchauffe, elle nous offre tous nos besoins primaires.\\\"\\n\\nPendant ce temps-là à Biras, en Dordogne, Pauline, Benjamin et Noéha vivent dans cette maison enterrée, autonome en énergie et bâtie avec des déchets. Visite de leur earthship.\\n\\n————————————— \\n▶︎ Retrouvez la vidéo sur le site de Brut https://www.brut.media/fr/science-and-technology/ils-vivent-dans-une-maison-batie-avec-des-dechets-cebe8641-ba94-4e76-843a-10b58e4a35fa\\n▶ 📲 sur l’appli Brut (iOS) : https://apple.co/2UY7gNH \\n▶ 📲 sur l’appli Brut (Android) : https://play.google.com/store/apps/details?id=media.brut.brut \\n👉 Abonnez-vous à la newsletter myBrut : https://bit.ly/2JhQ5pP\\n▶ Pour ne rien louper des vidéos Brut, n’hésitez pas à vous abonner ➞ https://www.youtube.com/channel/UCSKdvgqdnj72_SLggp7BDTg/?sub_confirmation=1 et à activer la cloche 🔔\"\n",
    "tags =  [\n",
    "      \"brut\",\n",
    "      \"déchet\",\n",
    "      \"maison\",\n",
    "      \"construction\",\n",
    "      \"poubelle\",\n",
    "      \"verre\",\n",
    "      \"recyclage\"\n",
    "    ]\n",
    "\n",
    "videoTestContexte = getContext(title, description, tags)\n",
    "\n",
    "#print(videoTestContexte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5e4cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de texte avec des noms de lieux\n",
    "texte_contenu = \"\"\"\n",
    "Lors de mon voyage en Provence, j’ai visité Marseille, le quartier du Panier, Aix-en-Provence \n",
    "et un petit village appelé Eygalières. Ensuite, nous sommes allés à Nice et dans le Vieux-Nice.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e70bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "getSpacialEntities_google(videoTestContexte,'MONO_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "getLLMresponse_ollama(texte_contenu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18695822",
   "metadata": {},
   "outputs": [],
   "source": [
    "getSpacialEntities_nvidia(videoTestContexte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0fe31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "getEntityVerification('biras','./csvs/v_commune_2025.csv','NCCENR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e28bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "getGeocoding('provence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d9dfe",
   "metadata": {},
   "source": [
    "- Run on All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7aa2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "runAll(\"./jsons/videosForSpacialAnalysis.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fef657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90b7747e",
   "metadata": {},
   "source": [
    "## Videos of non pertinents channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccabfc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedVideos = openJson(\"./jsons/updatedVideos.json\")\n",
    "len(updatedVideos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(\n",
    "    dbname=\"youtubestay\",\n",
    "    user=\"postgres\",\n",
    "    password=os.getenv(\"POSTGRE_PASSWORD\"),\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT v.id_video\n",
    "    FROM videos v join chaines c\n",
    "    ON v.id_chaine = c.id_chaine\n",
    "    WHERE c.pertinente= false ;\n",
    "\"\"\")\n",
    "\n",
    "rows = cur.fetchall()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "ids = [row[0] for row in rows]\n",
    "cleaned = []\n",
    "len(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c8402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in updatedVideos:\n",
    "    if video['id_video'] not in ids:\n",
    "            cleaned.append(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652c8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveJson(\"./jsons/updatedVideos.json\",cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e11f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "videosForSpacialAnalysis = openJson(\"./jsons/updatedVideos.json\")\n",
    "len(updatedVideos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6105a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9386ca47",
   "metadata": {},
   "source": [
    "### Plot coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "location_data = {\n",
    "        \"lat\": 49.5532646,\n",
    "        \"lon\": 2.9392577,\n",
    "        \"ent\": \"ville\"\n",
    "      }\n",
    "\n",
    "map_obj = folium.Map(location=[location_data[\"lat\"], location_data[\"lon\"]], zoom_start=13)\n",
    "\n",
    "folium.Marker(\n",
    "    [location_data[\"lat\"], location_data[\"lon\"]],\n",
    "    popup=location_data[\"ent\"],\n",
    "    tooltip=location_data[\"ent\"]\n",
    ").add_to(map_obj)\n",
    "\n",
    "map_obj.save(\"map_janze.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f750c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agrotube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
