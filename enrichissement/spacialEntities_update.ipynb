{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354aa2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from tqdm import tqdm \n",
    "from colorama import Style,Fore\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a84459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openJson(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def saveJson(path,data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "       json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "       print(Style.BRIGHT+Fore.GREEN+'\\n json saved'+Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86223f53",
   "metadata": {},
   "source": [
    "# Update DB with the new tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fdfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(\n",
    "    dbname=\"youtubestay\",\n",
    "    user=\"postgres\",\n",
    "    password=os.getenv(\"POSTGRE_PASSWORD\"),\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE entites_spatiales (\n",
    "        id_entite_spatiale TEXT PRIMARY KEY,\n",
    "        label TEXT NOT NULL,\n",
    "        latitude FLOAT NOT NULL,\n",
    "        longitude FLOAT NOT NULL \n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE entites_spatiales_videos (\n",
    "        id_entite_spatiale TEXT REFERENCES entites_spatiales(id_entite_spatiale) ON DELETE CASCADE,\n",
    "        id_video TEXT REFERENCES videos(id_video) ON DELETE CASCADE,\n",
    "        PRIMARY KEY (id_video, id_entite_spatiale)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE entites_spatiales_chaines (\n",
    "        id_entite_spatiale TEXT REFERENCES entites_spatiales(id_entite_spatiale) ON DELETE CASCADE,\n",
    "        id_chaine TEXT REFERENCES chaines(id_chaine) ON DELETE CASCADE,\n",
    "        PRIMARY KEY (id_chaine, id_entite_spatiale)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2bf7d5",
   "metadata": {},
   "source": [
    "# Fill the spacial_entities_videos table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05e82b7",
   "metadata": {},
   "source": [
    "## Prepare json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ca2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(\n",
    "    dbname=\"youtubestay\",\n",
    "    user=\"postgres\",\n",
    "    password=os.getenv(\"POSTGRE_PASSWORD\"),\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT id_video,titre,description,tags FROM videos\")\n",
    "rows = cur.fetchall()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "videos = []\n",
    "for row in rows:\n",
    "    id_video, titre, description, tags = row\n",
    "    videos.append({\n",
    "        \"id_video\": id_video,\n",
    "        \"titre\": titre,\n",
    "        \"description\": description,\n",
    "        \"tags\": tags\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ab7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f74e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveJson('./jsons/videosForSpacialAnalysis.json',videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae3c201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09b1a481",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d88e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_template = \"\"\"\n",
    "Tu es un extracteur d'entités géographiques françaises.\n",
    "À partir d’un texte donné, identifie uniquement les **villes**, **communes** situés en France.\n",
    "Ne prends **pas** en compte :\n",
    "- les noms de pays (ex: \"France\"),\n",
    "- les noms de personnes,\n",
    "- les noms de chaînes YouTube, de plateformes (ex: YouTube, Tipeee),\n",
    "- les noms imaginaires ou poétiques.\n",
    "\n",
    "Retourne une **liste Python**, en minuscules, sans doublons, contenant uniquement des noms de lieux réels en France.\n",
    "Pas d'explication, donner la reponse en format string.\n",
    "\n",
    "**Les noms extraits doivent être en français**\n",
    "**Pas d'explication juste la liste**\n",
    "\"\"\"\n",
    "\n",
    "user_template = \"Contexte : {contexte}\"\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(system_template)\n",
    "user_message = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, user_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4095710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm_ollama = ChatOllama(model=\"llama3.2:3b\")\n",
    "chain_ollama =  chat_prompt | llm_ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "llm_nvidia = ChatNVIDIA(\n",
    "  model=\"meta/llama-3.1-8b-instruct\",\n",
    "  api_key=os.getenv('NVIDIA_API_KEY'), \n",
    "  temperature=0,\n",
    "  top_p=0.7,\n",
    ")\n",
    "\n",
    "chain_nvidia =  chat_prompt | llm_nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe59faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66227fb6",
   "metadata": {},
   "source": [
    "{\n",
    "    id_video = '',\n",
    "    titre : '',\n",
    "    description:'',\n",
    "    tags:''\n",
    "    +\n",
    "    output : [\n",
    "            {\n",
    "            ent : Ent1\n",
    "            lat :\n",
    "            lon : },\n",
    "            {\n",
    "            ent : Ent2\n",
    "            lat :\n",
    "            lon : },\n",
    "        ...\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1068c490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updatedVideos = openJson(\"./jsons/updatedVideos.json\")\n",
    "len(updatedVideos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52295510",
   "metadata": {},
   "outputs": [],
   "source": [
    "startFrom = len(updatedVideos)\n",
    "\n",
    "def getContext(title,description,tags):\n",
    "    videoContext = ''\n",
    "    videoContext+=title\n",
    "    videoContext+= '\\n'+description\n",
    "    if tags:\n",
    "        videoContext += '\\n'+ ', '.join(tags)\n",
    "    return videoContext\n",
    "\n",
    "def getEntityVerification(entity,csvfile,column):\n",
    "    with open(csvfile, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if row[column].strip().lower() == entity:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def getLLMresponse(context,suffix):\n",
    "    llm_gemini = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite-preview-06-17\", temperature=0,api_key=os.getenv('GEMINI_API_KEY_'+suffix))\n",
    "    chain_gemini =  chat_prompt | llm_gemini\n",
    "    response = chain_gemini.invoke({'contexte':context})\n",
    "    #print('response ',response)\n",
    "    return response\n",
    "    \n",
    "def getSpacialEntities(context,suffix):\n",
    "    response = getLLMresponse(context,suffix)\n",
    "    \n",
    "    try:\n",
    "        entities = eval(response.content.strip())\n",
    "        if isinstance(entities, list):\n",
    "            Entities = []\n",
    "            for e in entities:\n",
    "                e_cleaned = e.lower().strip()\n",
    "                if getEntityVerification(e_cleaned,'./csvs/v_commune_2025.csv','NCCENR'):\n",
    "                    Entities.append(e_cleaned)\n",
    "            return Entities\n",
    "    except:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def getGeocoding(entity):\n",
    "    url = \"https://nominatim.openstreetmap.org/search\"\n",
    "    params = {\n",
    "        \"q\": entity + \", France\",\n",
    "        \"format\": \"json\",\n",
    "        \"limit\": 1\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"geo-entity-extractor/1.0\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            lat = float(data[0][\"lat\"])\n",
    "            lon = float(data[0][\"lon\"])\n",
    "            return {'lat':lat,\n",
    "                    'lon':lon}\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur pour l'entité '{entity}': {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def runAll(jsonfile):\n",
    "    videos = openJson(jsonfile)\n",
    "    counter = 0\n",
    "    MyAPIsuffix = ['MONO','NOUR','NOUR2008','TEXTRA','ZEG']\n",
    "    index = 0\n",
    "    apiCounter = 0\n",
    "    updatedVideos = openJson(\"./jsons/updatedVideos.json\") # We open the old jsonfile so we continue from the video we stopped in.\n",
    "    \n",
    "    for video in tqdm(videos[startFrom:]):\n",
    "        videoContext = getContext(video['titre'],video['description'],video['tags'])\n",
    "        \n",
    "        videoSpacialEntities = getSpacialEntities(videoContext,MyAPIsuffix[index])\n",
    "        \n",
    "        #print(\"videoSpacialEntities  \",videoSpacialEntities)\n",
    "        if len(videoSpacialEntities) > 0:\n",
    "            output = []\n",
    "            for ent in videoSpacialEntities:\n",
    "                geocoding = getGeocoding(ent)\n",
    "                if geocoding :\n",
    "                    geocoding['ent']=ent\n",
    "                    output.append(geocoding)\n",
    "            if len(output) >0 :\n",
    "                video['output'] = output\n",
    "                \n",
    "        # Updating the new list\n",
    "        updatedVideos.append(video)\n",
    "        \n",
    "        # Safe Saving \n",
    "        counter+= 1\n",
    "        if counter == 100:\n",
    "            saveJson(\"./jsons/updatedVideos.json\",updatedVideos)\n",
    "            counter =0\n",
    "            \n",
    "        # API Switching\n",
    "        apiCounter +=1\n",
    "        if apiCounter == 13:\n",
    "            index+=1\n",
    "            apiCounter = 0\n",
    "            if index==5:\n",
    "                print(Style.BRIGHT+Fore.BLUE+'\\n sleep for 60s'+Style.RESET_ALL)\n",
    "                time.sleep(60)\n",
    "                index=0\n",
    "            print(Style.BRIGHT+Fore.YELLOW+f'\\n API KEY switched to {MyAPIsuffix[index]}'+Style.RESET_ALL)\n",
    "\n",
    "    # Saving \n",
    "    saveJson(\"./jsons/updatedVideos.json\",updatedVideos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb943e",
   "metadata": {},
   "source": [
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1382096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Ils vivent dans une maison bâtie avec des déchets\"\n",
    "description = \"\\\"Elle nous protège, elle nous nourrit, elle nous réchauffe, elle nous offre tous nos besoins primaires.\\\"\\n\\nPendant ce temps-là à Biras, en Dordogne, Pauline, Benjamin et Noéha vivent dans cette maison enterrée, autonome en énergie et bâtie avec des déchets. Visite de leur earthship.\\n\\n————————————— \\n▶︎ Retrouvez la vidéo sur le site de Brut https://www.brut.media/fr/science-and-technology/ils-vivent-dans-une-maison-batie-avec-des-dechets-cebe8641-ba94-4e76-843a-10b58e4a35fa\\n▶ 📲 sur l’appli Brut (iOS) : https://apple.co/2UY7gNH \\n▶ 📲 sur l’appli Brut (Android) : https://play.google.com/store/apps/details?id=media.brut.brut \\n👉 Abonnez-vous à la newsletter myBrut : https://bit.ly/2JhQ5pP\\n▶ Pour ne rien louper des vidéos Brut, n’hésitez pas à vous abonner ➞ https://www.youtube.com/channel/UCSKdvgqdnj72_SLggp7BDTg/?sub_confirmation=1 et à activer la cloche 🔔\"\n",
    "tags =  [\n",
    "      \"brut\",\n",
    "      \"déchet\",\n",
    "      \"maison\",\n",
    "      \"construction\",\n",
    "      \"poubelle\",\n",
    "      \"verre\",\n",
    "      \"recyclage\"\n",
    "    ]\n",
    "\n",
    "videoTestContexte = getContext(title, description, tags)\n",
    "\n",
    "#print(videoTestContexte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e4cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de texte avec des noms de lieux\n",
    "texte_contenu = \"\"\"\n",
    "Lors de mon voyage en Provence, j’ai visité Marseille, le quartier du Panier, Aix-en-Provence \n",
    "et un petit village appelé Eygalières. Ensuite, nous sommes allés à Nice et dans le Vieux-Nice.\n",
    "\"\"\"\n",
    "\n",
    "getSpacialEntities(videoTestContexte,'MONO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0fe31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "getEntityVerification('biras','./csvs/v_commune_2025.csv','NCCENR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e28bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "getGeocoding('aix-en-provence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d9dfe",
   "metadata": {},
   "source": [
    "- Run on All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7aa2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "runAll(\"./jsons/videosForSpacialAnalysis.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fef657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9386ca47",
   "metadata": {},
   "source": [
    "### Plot coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "location_data = {\n",
    "        \"lat\": 49.5532646,\n",
    "        \"lon\": 2.9392577,\n",
    "        \"ent\": \"ville\"\n",
    "      }\n",
    "\n",
    "map_obj = folium.Map(location=[location_data[\"lat\"], location_data[\"lon\"]], zoom_start=13)\n",
    "\n",
    "folium.Marker(\n",
    "    [location_data[\"lat\"], location_data[\"lon\"]],\n",
    "    popup=location_data[\"ent\"],\n",
    "    tooltip=location_data[\"ent\"]\n",
    ").add_to(map_obj)\n",
    "\n",
    "map_obj.save(\"map_janze.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f750c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agrotube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
