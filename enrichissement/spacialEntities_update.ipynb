{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354aa2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from tqdm import tqdm \n",
    "from colorama import Style,Fore\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a84459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openJson(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def saveJson(path,data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "       json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "       print(Style.BRIGHT+Fore.GREEN+'\\n json saved'+Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86223f53",
   "metadata": {},
   "source": [
    "# Update DB with the new tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fdfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(\n",
    "    dbname=\"youtubestay\",\n",
    "    user=\"postgres\",\n",
    "    password=os.getenv(\"POSTGRE_PASSWORD\"),\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE entites_spatiales (\n",
    "        id_entite_spatiale TEXT PRIMARY KEY,\n",
    "        label TEXT NOT NULL,\n",
    "        latitude FLOAT NOT NULL,\n",
    "        longitude FLOAT NOT NULL \n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE entites_spatiales_videos (\n",
    "        id_entite_spatiale TEXT REFERENCES entites_spatiales(id_entite_spatiale) ON DELETE CASCADE,\n",
    "        id_video TEXT REFERENCES videos(id_video) ON DELETE CASCADE,\n",
    "        PRIMARY KEY (id_video, id_entite_spatiale)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE entites_spatiales_chaines (\n",
    "        id_entite_spatiale TEXT REFERENCES entites_spatiales(id_entite_spatiale) ON DELETE CASCADE,\n",
    "        id_chaine TEXT REFERENCES chaines(id_chaine) ON DELETE CASCADE,\n",
    "        PRIMARY KEY (id_chaine, id_entite_spatiale)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2bf7d5",
   "metadata": {},
   "source": [
    "# Fill the spacial_entities_videos table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05e82b7",
   "metadata": {},
   "source": [
    "## Prepare json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ca2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(\n",
    "    dbname=\"youtubestay\",\n",
    "    user=\"postgres\",\n",
    "    password=os.getenv(\"POSTGRE_PASSWORD\"),\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "SELECT v.id_video,v.titre,v.description,v.tags \n",
    "FROM videos v JOIN chaines c ON v.id_chaine = c.id_chaine\n",
    "WHERE c.pertinente = true;\n",
    "\"\"\"\n",
    ")\n",
    "rows = cur.fetchall()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "videos = []\n",
    "for row in rows:\n",
    "    id_video, titre, description, tags = row\n",
    "    videos.append({\n",
    "        \"id_video\": id_video,\n",
    "        \"titre\": titre,\n",
    "        \"description\": description,\n",
    "        \"tags\": tags\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ab7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f74e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveJson('./jsons/videosForSpacialAnalysis.json',videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d52263",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc29a0f",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dccb0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_template = \"\"\"\n",
    "Tu es un extracteur d'entités géographiques.\n",
    "\n",
    "À partir d’un texte donné, identifie toutes les localisations situées en France.\n",
    "\n",
    "Ignore :\n",
    "- les noms de pays (ex : \"France\"),\n",
    "- les noms de personnes,\n",
    "- les noms de chaînes YouTube, plateformes ou services numériques (ex : YouTube, Tipeee),\n",
    "- les noms imaginaires, poétiques ou fictifs.\n",
    "\n",
    "Retourne uniquement une **liste Python**, en **minuscules**, **sans doublons**, contenant **uniquement** des noms de lieux **réels** situés en **France**.\n",
    "\n",
    "Aucune explication. **Donne uniquement le résultat au format requis.**\n",
    "\"\"\"\n",
    "\n",
    "user_template = \"Contexte : {contexte}\"\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(system_template)\n",
    "user_message = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, user_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02501013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "llm_nvidia = ChatNVIDIA(\n",
    "  model=\"meta/llama-3.1-8b-instruct\",\n",
    "  api_key=os.getenv('NVIDIA_API_KEY'), \n",
    "  temperature=0,\n",
    "  top_p=0.7,\n",
    ")\n",
    "\n",
    "chain_nvidia =  chat_prompt | llm_nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08dfb644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm_ollama = ChatOllama(model=\"mistral-nemo:12b\")\n",
    "chain_ollama =  chat_prompt | llm_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3a1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bae7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedVideosNew = openJson(\"./jsons/updatedVideosNew.json\")\n",
    "len(updatedVideosNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dae3c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "startFrom = len(updatedVideosNew)\n",
    "\n",
    "def getContext(title,description,tags):\n",
    "    videoContext = ''\n",
    "    videoContext+=title\n",
    "    videoContext+= '\\n'+description\n",
    "    if tags:\n",
    "        videoContext += '\\n'+ ', '.join(tags)\n",
    "    return videoContext\n",
    "\n",
    "def getLLMresponse_google(context,suffix):\n",
    "    llm_gemini = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite-preview-06-17\", temperature=0,api_key=os.getenv('GEMINI_API_KEY_'+suffix))\n",
    "    chain_gemini =  chat_prompt | llm_gemini\n",
    "    response = chain_gemini.invoke({'contexte':context})\n",
    "    #print('response ',response)\n",
    "    return response\n",
    "  \n",
    "def getLLMresponse_nvidia(context):\n",
    "    response = chain_nvidia.invoke({'contexte':context})\n",
    "    #print('response ',response)\n",
    "    return response\n",
    "\n",
    "def getLLMresponse_ollama(context):\n",
    "    response = chain_ollama.invoke({'contexte':context})\n",
    "    #print('response ',response)\n",
    "    return response\n",
    "\n",
    "def getSpacialEntities_google(context,suffix):\n",
    "    response = getLLMresponse_google(context,suffix)\n",
    "    \n",
    "    try:\n",
    "        entities = eval(response.content.strip())\n",
    "        if isinstance(entities, list):\n",
    "            Entities = []\n",
    "            for e in entities:\n",
    "                e_cleaned = e.lower().strip()\n",
    "                Entities.append(e_cleaned)\n",
    "            return Entities\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def getSpacialEntities_nvidia(context):\n",
    "    response = getLLMresponse_nvidia(context)\n",
    "    \n",
    "    try:\n",
    "        entities = eval(response.content.strip())\n",
    "        if isinstance(entities, list):\n",
    "            Entities = []\n",
    "            for e in entities:\n",
    "                e_cleaned = e.lower().strip()\n",
    "                Entities.append(e_cleaned)\n",
    "            return Entities\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def getSpacialEntities_ollama(context):\n",
    "    response = getLLMresponse_ollama(context)\n",
    "    \n",
    "    try:\n",
    "        entities = eval(response.content.strip())\n",
    "        if isinstance(entities, list):\n",
    "            Entities = []\n",
    "            for e in entities:\n",
    "                e_cleaned = e.lower().strip()\n",
    "                Entities.append(e_cleaned)\n",
    "            return Entities\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def getGeocoding(entity):\n",
    "    url = \"https://nominatim.openstreetmap.org/search\"\n",
    "    params = {\n",
    "        \"q\": entity,\n",
    "        \"format\": \"json\",\n",
    "        \"limit\": 1,\n",
    "        \"addressdetails\": 1\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"geo-entity-extractor/1.0\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            lat = float(data[0][\"lat\"])\n",
    "            lon = float(data[0][\"lon\"])\n",
    "            country = data[0].get(\"address\", {}).get(\"country\", \"unknown\")\n",
    "            return {\n",
    "                'lat': lat,\n",
    "                'lon': lon,\n",
    "                'country': country\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur pour l'entité '{entity}': {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def runAll(jsonfile):\n",
    "    videos = openJson(jsonfile)\n",
    "    counter = 0\n",
    "    MyAPIsuffix = ['MONO','NOUR','NOUR2008','TEXTRA','ZEG']\n",
    "    #MyAPIsuffix = ['MONO_1','MONO_2','MONO_3','MONO_4','MONO_5']\n",
    "    index = 0\n",
    "    apiCounter = 0\n",
    "    \n",
    "    updatedVideosNew = openJson(\"./jsons/updatedVideosNew.json\") # We open the old jsonfile so we continue from the video we stopped in.\n",
    "    \n",
    "    for video in tqdm(videos[startFrom:]):\n",
    "        videoContext = getContext(video['titre'],video['description'],video['tags'])\n",
    "        \n",
    "        videoSpacialEntities = getSpacialEntities_google(videoContext,MyAPIsuffix[index])\n",
    "        \n",
    "        time.sleep(2)\n",
    "        #videoSpacialEntities = getSpacialEntities_nvidia(videoContext)\n",
    "        #videoSpacialEntities = getSpacialEntities_ollama(videoContext)\n",
    "        \n",
    "        #print(\"videoSpacialEntities  \",videoSpacialEntities)\n",
    "        \n",
    "        if videoSpacialEntities and len(videoSpacialEntities) > 0:\n",
    "            output = []\n",
    "            for ent in videoSpacialEntities:\n",
    "                geocoding = getGeocoding(ent)\n",
    "                if geocoding and geocoding['country']=='France':\n",
    "                    geocoding['ent']=ent\n",
    "                    output.append(geocoding)\n",
    "            if len(output) >0 :\n",
    "                video['output'] = output\n",
    "                \n",
    "        # Updating the new list\n",
    "        updatedVideosNew.append(video)\n",
    "        \n",
    "        # Safe Saving \n",
    "        counter+= 1\n",
    "        if counter == 20:\n",
    "            saveJson(\"./jsons/updatedVideosNew.json\",updatedVideosNew)\n",
    "            counter =0\n",
    "            \n",
    "        # API Switching\n",
    "        \n",
    "        apiCounter +=1\n",
    "        if apiCounter == 13:\n",
    "            index+=1\n",
    "            apiCounter = 0\n",
    "            if index==len(MyAPIsuffix):\n",
    "                print(Style.BRIGHT+Fore.BLUE+'\\n sleep for 60s'+Style.RESET_ALL)\n",
    "                time.sleep(60)\n",
    "                index=0\n",
    "            print(Style.BRIGHT+Fore.YELLOW+f'\\n API KEY switched to {MyAPIsuffix[index]}'+Style.RESET_ALL)\n",
    "            \n",
    "        \"\"\"\n",
    "        apiCounter +=1\n",
    "        if apiCounter == 35:\n",
    "            print(Style.BRIGHT+Fore.BLUE+'\\n sleep for 60s'+Style.RESET_ALL)\n",
    "            time.sleep(60)\n",
    "            apiCounter = 0\n",
    "        \"\"\"\n",
    "        \n",
    "    # Saving \n",
    "    saveJson(\"./jsons/updatedVideosNew.json\",updatedVideosNew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee17be8",
   "metadata": {},
   "source": [
    "### Run on some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72180564",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = openJson('./jsons/test.json')\n",
    "len(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyAPIsuffix = ['MONO_1','MONO_2','MONO_3','MONO_4','MONO_5']\n",
    "index = 0\n",
    "apiCounter = 0\n",
    "\n",
    "for video in tqdm(testData):\n",
    "    output = []\n",
    "    context = getContext(video['titre'],video['description'],video['tags'])\n",
    "    entities = getSpacialEntities_google(context,MyAPIsuffix[index])\n",
    "    #entities = getSpacialEntities_ollama(context)\n",
    "    print('entities :',entities)\n",
    "    if entities:\n",
    "        for ent in entities:\n",
    "            result = {'ent':ent}\n",
    "            geoCode = getGeocoding(ent)\n",
    "            if geoCode:\n",
    "                result.update(geoCode)\n",
    "            output.append(result)\n",
    "            #print('output  :',output)\n",
    "    video['output'] = output\n",
    "            \n",
    "    # API Switching\n",
    "     \n",
    "    apiCounter +=1\n",
    "    if apiCounter == 13:\n",
    "        index+=1\n",
    "        apiCounter = 0\n",
    "        if index==5:\n",
    "            print(Style.BRIGHT+Fore.BLUE+'\\n sleep for 60s'+Style.RESET_ALL)\n",
    "            time.sleep(60)\n",
    "            index=0\n",
    "        print(Style.BRIGHT+Fore.YELLOW+f'\\n API KEY switched to {MyAPIsuffix[index]}'+Style.RESET_ALL)\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveJson('./jsons/testResults.json',testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05730a4c",
   "metadata": {},
   "source": [
    "### Plot in map an Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0e1c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "location_data = {\n",
    "        \"ent\": \"brian\",\n",
    "        \"lat\": 45.5913283,\n",
    "        \"lon\": 12.8142248,\n",
    "      }\n",
    "map_obj = folium.Map(location=[location_data[\"lat\"], location_data[\"lon\"]], zoom_start=13)\n",
    "\n",
    "folium.Marker(\n",
    "    [location_data[\"lat\"], location_data[\"lon\"]],\n",
    "    popup=location_data[\"ent\"],\n",
    "    tooltip=location_data[\"ent\"]\n",
    ").add_to(map_obj)\n",
    "\n",
    "map_obj.save(\"map_janze.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4b93e5",
   "metadata": {},
   "source": [
    "### Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ef97f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3510/20563 [3:32:45<97:48:38, 20.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3520/20563 [3:33:09<14:54:16,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3523/20563 [3:33:17<12:54:28,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3536/20563 [3:33:47<11:16:39,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3540/20563 [3:33:58<12:45:51,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3549/20563 [3:34:19<11:09:09,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3560/20563 [3:34:46<12:35:35,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3562/20563 [3:34:51<12:02:03,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3574/20563 [3:35:20<11:14:10,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3575/20563 [3:36:22<96:06:34, 20.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3580/20563 [3:36:35<26:52:25,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3588/20563 [3:36:54<12:06:15,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3600/20563 [3:37:24<12:46:32,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3601/20563 [3:37:27<12:17:48,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3614/20563 [3:37:59<11:49:13,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3620/20563 [3:38:15<12:37:10,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3627/20563 [3:38:31<11:31:43,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3639/20563 [3:39:00<11:15:50,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3640/20563 [3:40:03<97:02:53, 20.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3653/20563 [3:40:34<11:48:22,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3660/20563 [3:40:51<12:10:29,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3666/20563 [3:41:06<11:40:29,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3679/20563 [3:41:37<11:37:16,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3680/20563 [3:41:40<12:57:23,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3692/20563 [3:42:10<13:17:04,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3700/20563 [3:42:30<12:18:43,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3704/20563 [3:42:40<11:24:23,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3705/20563 [3:43:42<95:35:59, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3718/20563 [3:44:13<12:16:40,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3720/20563 [3:44:19<12:51:20,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3731/20563 [3:44:45<11:01:59,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3740/20563 [3:45:09<12:43:09,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3744/20563 [3:45:18<11:15:32,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3757/20563 [3:45:52<12:38:21,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3760/20563 [3:46:01<13:23:40,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3769/20563 [3:46:26<13:22:27,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3770/20563 [3:47:28<96:23:10, 20.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3780/20563 [3:47:53<15:06:36,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3783/20563 [3:48:03<15:08:44,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3796/20563 [3:48:42<14:47:19,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3800/20563 [3:49:00<20:17:58,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 3809/20563 [3:49:34<18:20:05,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 3820/20563 [3:50:09<15:33:19,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 3822/20563 [3:50:14<13:06:16,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 3834/20563 [3:50:45<11:25:11,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 3835/20563 [3:51:47<94:57:42, 20.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 3840/20563 [3:52:00<26:16:24,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 3848/20563 [3:52:19<11:51:54,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3860/20563 [3:52:54<14:48:38,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3861/20563 [3:52:58<15:03:30,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3874/20563 [3:53:33<11:43:08,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3880/20563 [3:53:48<12:23:59,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3887/20563 [3:54:15<19:47:40,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3899/20563 [3:54:46<11:31:48,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3900/20563 [3:55:49<96:04:41, 20.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3913/20563 [3:56:22<11:52:04,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3920/20563 [3:56:46<13:34:35,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3926/20563 [3:57:01<11:21:39,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3939/20563 [3:57:32<11:27:01,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3940/20563 [3:57:36<12:23:20,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3952/20563 [3:58:06<11:00:36,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3960/20563 [3:58:26<11:57:09,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3964/20563 [3:58:35<11:32:31,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3965/20563 [3:59:38<94:20:34, 20.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3978/20563 [4:00:09<12:12:24,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3980/20563 [4:00:15<13:20:47,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3991/20563 [4:00:42<11:09:53,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 4000/20563 [4:01:04<12:11:23,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 4004/20563 [4:01:14<11:14:51,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4017/20563 [4:01:46<11:52:11,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4020/20563 [4:01:54<12:23:25,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4029/20563 [4:02:16<11:00:26,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4030/20563 [4:03:18<93:41:47, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4040/20563 [4:03:48<20:55:28,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4043/20563 [4:03:55<14:33:10,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4056/20563 [4:04:47<12:52:13,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4060/20563 [4:04:59<13:28:57,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4069/20563 [4:06:59<44:22:15,  9.68s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4080/20563 [4:07:26<12:36:06,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4082/20563 [4:07:33<14:36:13,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4094/20563 [4:08:02<11:03:35,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4095/20563 [4:09:04<93:19:00, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4100/20563 [4:09:17<26:22:14,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4108/20563 [4:09:40<12:48:26,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4120/20563 [4:10:10<11:45:42,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4121/20563 [4:10:13<11:47:47,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4134/20563 [4:10:46<11:39:57,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4140/20563 [4:11:02<12:16:46,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4147/20563 [4:11:19<11:01:20,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4159/20563 [4:11:49<11:19:42,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4160/20563 [4:12:52<94:28:59, 20.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4173/20563 [4:13:23<11:40:32,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4180/20563 [4:13:41<12:16:10,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4186/20563 [4:13:55<11:08:04,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4199/20563 [4:14:31<11:40:20,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4200/20563 [4:14:34<12:52:45,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4212/20563 [4:15:03<10:42:52,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4220/20563 [4:15:29<16:12:58,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4224/20563 [4:15:40<13:19:13,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4225/20563 [4:16:42<94:07:12, 20.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4238/20563 [4:17:23<14:34:06,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4240/20563 [4:17:29<15:00:57,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4251/20563 [4:18:01<12:45:27,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4260/20563 [4:18:27<13:04:39,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4264/20563 [4:18:41<15:15:41,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4277/20563 [4:19:14<11:23:00,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4280/20563 [4:19:23<12:50:49,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4289/20563 [4:19:47<12:09:11,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4290/20563 [4:20:49<93:23:02, 20.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4300/20563 [4:21:18<15:39:08,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4303/20563 [4:21:26<13:04:18,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4316/20563 [4:22:03<12:50:51,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4320/20563 [4:22:15<13:18:41,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4329/20563 [4:22:39<12:17:18,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4340/20563 [4:23:21<17:55:04,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4342/20563 [4:23:28<17:28:30,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4354/20563 [4:23:59<10:52:14,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4355/20563 [4:25:02<92:10:33, 20.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4360/20563 [4:25:14<25:30:49,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4368/20563 [4:25:33<11:21:46,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 4380/20563 [4:26:03<11:54:48,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 4381/20563 [4:26:06<11:36:58,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 4394/20563 [4:26:37<11:10:45,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 4400/20563 [4:26:52<11:51:46,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 4407/20563 [4:27:09<10:46:42,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 4419/20563 [4:27:38<10:45:18,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 4420/20563 [4:28:42<92:41:28, 20.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4433/20563 [4:29:14<12:00:14,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4440/20563 [4:29:32<12:55:50,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4446/20563 [4:29:46<10:54:39,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4459/20563 [4:30:17<10:51:43,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4460/20563 [4:30:20<11:55:52,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4472/20563 [4:30:49<10:39:00,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4480/20563 [4:31:09<12:00:58,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4484/20563 [4:31:18<10:41:14,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4485/20563 [4:32:21<91:06:35, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4498/20563 [4:32:51<11:03:11,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4500/20563 [4:32:57<12:09:13,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4511/20563 [4:33:24<10:47:21,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4520/20563 [4:33:47<11:50:31,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4524/20563 [4:33:57<11:00:41,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4537/20563 [4:34:30<10:46:12,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4540/20563 [4:34:38<12:19:27,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4549/20563 [4:35:00<11:49:49,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4550/20563 [4:36:03<91:37:45, 20.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4560/20563 [4:36:27<14:06:00,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4563/20563 [4:36:35<12:01:24,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4576/20563 [4:37:06<10:36:06,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4580/20563 [4:37:17<11:56:44,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4589/20563 [4:37:38<10:42:08,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4600/20563 [4:38:06<11:49:17,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4602/20563 [4:38:11<11:40:07,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4614/20563 [4:38:41<11:36:01,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4615/20563 [4:39:44<91:02:23, 20.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4620/20563 [4:39:57<25:19:02,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4628/20563 [4:40:16<12:16:48,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4640/20563 [4:40:48<11:50:43,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4641/20563 [4:40:50<11:23:22,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4654/20563 [4:41:21<10:10:26,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4660/20563 [4:41:36<11:39:26,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4667/20563 [4:41:55<12:01:56,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4679/20563 [4:42:29<11:54:20,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4680/20563 [4:43:32<91:59:50, 20.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4693/20563 [4:44:07<12:30:30,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4700/20563 [4:44:27<13:10:18,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4706/20563 [4:44:44<12:27:15,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4719/20563 [4:45:18<10:51:33,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4720/20563 [4:45:21<12:01:36,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4732/20563 [4:45:50<10:11:24,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4740/20563 [4:46:10<11:51:41,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4744/20563 [4:46:21<11:56:14,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4745/20563 [4:47:24<91:17:02, 20.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4758/20563 [4:47:58<11:52:49,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4760/20563 [4:48:04<12:18:25,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4771/20563 [4:48:31<11:42:16,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4780/20563 [4:48:54<11:38:58,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4784/20563 [4:49:04<11:27:47,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4797/20563 [4:49:39<11:13:22,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4800/20563 [4:49:47<11:41:29,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4809/20563 [4:50:08<10:40:47,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4810/20563 [4:51:11<89:26:36, 20.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4820/20563 [4:51:35<13:31:20,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4823/20563 [4:51:43<11:26:53,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4836/20563 [4:52:25<13:56:39,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4840/20563 [4:52:41<16:42:08,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4849/20563 [4:53:07<11:25:31,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4860/20563 [4:53:35<12:10:49,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4862/20563 [4:53:40<11:31:23,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4874/20563 [4:54:08<9:59:46,  2.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4875/20563 [4:55:11<88:39:01, 20.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4880/20563 [4:55:23<24:33:09,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4888/20563 [4:55:43<12:14:01,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4900/20563 [4:56:13<11:34:35,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4901/20563 [4:56:15<11:09:45,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to NOUR2008\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4914/20563 [4:56:45<10:09:41,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to TEXTRA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4920/20563 [4:57:01<11:28:02,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4927/20563 [4:57:17<10:28:02,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to ZEG\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4939/20563 [4:57:46<10:19:11,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      " sleep for 60s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4940/20563 [4:58:50<90:31:38, 20.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m\n",
      " API KEY switched to MONO\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4952/20563 [4:59:19<11:24:19,  2.63s/it]Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "].\n",
      " 24%|██▍       | 4952/20563 [4:59:22<15:43:44,  3.63s/it]\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 44\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrunAll\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./jsons/videosForSpacialAnalysis.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 116\u001b[0m, in \u001b[0;36mrunAll\u001b[0;34m(jsonfile)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video \u001b[38;5;129;01min\u001b[39;00m tqdm(videos[startFrom:]):\n\u001b[1;32m    114\u001b[0m     videoContext \u001b[38;5;241m=\u001b[39m getContext(video[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitre\u001b[39m\u001b[38;5;124m'\u001b[39m],video[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m],video[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 116\u001b[0m     videoSpacialEntities \u001b[38;5;241m=\u001b[39m \u001b[43mgetSpacialEntities_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideoContext\u001b[49m\u001b[43m,\u001b[49m\u001b[43mMyAPIsuffix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m#videoSpacialEntities = getSpacialEntities_nvidia(videoContext)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m#videoSpacialEntities = getSpacialEntities_ollama(videoContext)\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m#print(\"videoSpacialEntities  \",videoSpacialEntities)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 29\u001b[0m, in \u001b[0;36mgetSpacialEntities_google\u001b[0;34m(context, suffix)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgetSpacialEntities_google\u001b[39m(context,suffix):\n\u001b[0;32m---> 29\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mgetLLMresponse_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m         entities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(response\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip())\n",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m, in \u001b[0;36mgetLLMresponse_google\u001b[0;34m(context, suffix)\u001b[0m\n\u001b[1;32m     12\u001b[0m llm_gemini \u001b[38;5;241m=\u001b[39m ChatGoogleGenerativeAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-2.5-flash-lite-preview-06-17\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGEMINI_API_KEY_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39msuffix))\n\u001b[1;32m     13\u001b[0m chain_gemini \u001b[38;5;241m=\u001b[39m  chat_prompt \u001b[38;5;241m|\u001b[39m llm_gemini\n\u001b[0;32m---> 14\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchain_gemini\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontexte\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#print('response ',response)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3034\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3032\u001b[0m                 \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3033\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3034\u001b[0m                 \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3036\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:1022\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.invoke\u001b[0;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1019\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTools are already defined.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_execution tool can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1020\u001b[0m         )\n\u001b[0;32m-> 1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:368\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    364\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    365\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    367\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 368\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    378\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:937\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    936\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:759\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    758\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 759\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m         )\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1002\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1002\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1006\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:1089\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1065\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1077\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m   1078\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m   1079\u001b[0m         messages,\n\u001b[1;32m   1080\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1087\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[1;32m   1088\u001b[0m     )\n\u001b[0;32m-> 1089\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:206\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/tenacity/__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/tenacity/__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/tenacity/__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/tenacity/__init__.py:420\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    418\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/tenacity/__init__.py:187\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/system/conda/miniconda3/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/system/conda/miniconda3/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/tenacity/__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:204\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:188\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:867\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    866\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/STAYProject/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 44\n}\n]"
     ]
    }
   ],
   "source": [
    "runAll(\"./jsons/videosForSpacialAnalysis.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89731422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09b1a481",
   "metadata": {},
   "source": [
    "## Old Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d88e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_template = \"\"\"\n",
    "Tu es un extracteur d'entités géographiques françaises.\n",
    "À partir d’un texte donné, identifie uniquement les **villes**, **communes** situés en France.\n",
    "Ne prends **pas** en compte :\n",
    "- les noms de pays (ex: \"France\"),\n",
    "- les noms de personnes,\n",
    "- les noms de chaînes YouTube, de plateformes (ex: YouTube, Tipeee),\n",
    "- les noms imaginaires ou poétiques.\n",
    "\n",
    "Retourne une **liste Python**, en minuscules, sans doublons, contenant uniquement des noms de lieux réels en France.\n",
    "Pas d'explication, donner la reponse en format string.\n",
    "\n",
    "**Les noms extraits doivent être en français**\n",
    "**Pas d'explication juste la liste**\n",
    "\"\"\"\n",
    "\n",
    "user_template = \"Contexte : {contexte}\"\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(system_template)\n",
    "user_message = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, user_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4095710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm_ollama = ChatOllama(model=\"llama3.1:8b\")\n",
    "chain_ollama =  chat_prompt | llm_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "llm_nvidia = ChatNVIDIA(\n",
    "  model=\"meta/llama-3.1-8b-instruct\",\n",
    "  api_key=os.getenv('NVIDIA_API_KEY'), \n",
    "  temperature=0,\n",
    "  top_p=0.7,\n",
    ")\n",
    "\n",
    "chain_nvidia =  chat_prompt | llm_nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe59faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66227fb6",
   "metadata": {},
   "source": [
    "{\n",
    "    id_video = '',\n",
    "    titre : '',\n",
    "    description:'',\n",
    "    tags:''\n",
    "    +\n",
    "    output : [\n",
    "            {\n",
    "            ent : Ent1\n",
    "            lat :\n",
    "            lon : },\n",
    "            {\n",
    "            ent : Ent2\n",
    "            lat :\n",
    "            lon : },\n",
    "        ...\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedVideos = openJson(\"./jsons/updatedVideos.json\")\n",
    "len(updatedVideos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52295510",
   "metadata": {},
   "outputs": [],
   "source": [
    "startFrom = len(updatedVideos)\n",
    "\n",
    "def getContext(title,description,tags):\n",
    "    videoContext = ''\n",
    "    videoContext+=title\n",
    "    videoContext+= '\\n'+description\n",
    "    if tags:\n",
    "        videoContext += '\\n'+ ', '.join(tags)\n",
    "    return videoContext\n",
    "\n",
    "def getEntityVerification(entity,csvfile,column):\n",
    "    with open(csvfile, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if row[column].strip().lower() == entity:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def getLLMresponse_google(context,suffix):\n",
    "    llm_gemini = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite-preview-06-17\", temperature=0,api_key=os.getenv('GEMINI_API_KEY_'+suffix))\n",
    "    chain_gemini =  chat_prompt | llm_gemini\n",
    "    response = chain_gemini.invoke({'contexte':context})\n",
    "    #print('response ',response)\n",
    "    return response\n",
    "   \n",
    "def getLLMresponse_nvidia(context):\n",
    "    response = chain_nvidia.invoke({'contexte':context})\n",
    "    #print('response ',response)\n",
    "    return response\n",
    "  \n",
    "def getSpacialEntities_google(context,suffix):\n",
    "    response = getLLMresponse_google(context,suffix)\n",
    "    \n",
    "    try:\n",
    "        entities = eval(response.content.strip())\n",
    "        if isinstance(entities, list):\n",
    "            Entities = []\n",
    "            for e in entities:\n",
    "                e_cleaned = e.lower().strip()\n",
    "                if getEntityVerification(e_cleaned,'./csvs/v_commune_2025.csv','NCCENR'):\n",
    "                    Entities.append(e_cleaned)\n",
    "            return Entities\n",
    "    except:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def getSpacialEntities_nvidia(context):\n",
    "    response = getLLMresponse_nvidia(context)\n",
    "    \n",
    "    try:\n",
    "        entities = eval(response.content.strip())\n",
    "        if isinstance(entities, list):\n",
    "            Entities = []\n",
    "            for e in entities:\n",
    "                e_cleaned = e.lower().strip()\n",
    "                if getEntityVerification(e_cleaned,'./csvs/v_commune_2025.csv','NCCENR'):\n",
    "                    Entities.append(e_cleaned)\n",
    "            return Entities\n",
    "    except:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def getGeocoding(entity):\n",
    "    url = \"https://nominatim.openstreetmap.org/search\"\n",
    "    params = {\n",
    "        \"q\": entity + \", France\",\n",
    "        \"format\": \"json\",\n",
    "        \"limit\": 1\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"geo-entity-extractor/1.0\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            lat = float(data[0][\"lat\"])\n",
    "            lon = float(data[0][\"lon\"])\n",
    "            return {'lat':lat,\n",
    "                    'lon':lon}\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur pour l'entité '{entity}': {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def runAll(jsonfile):\n",
    "    videos = openJson(jsonfile)\n",
    "    counter = 0\n",
    "    MyAPIsuffix = ['MONO','NOUR','NOUR2008','TEXTRA','ZEG']\n",
    "    index = 0\n",
    "    apiCounter = 0\n",
    "    \n",
    "    updatedVideos = openJson(\"./jsons/updatedVideos.json\") # We open the old jsonfile so we continue from the video we stopped in.\n",
    "    \n",
    "    for video in tqdm(videos[startFrom:]):\n",
    "        videoContext = getContext(video['titre'],video['description'],video['tags'])\n",
    "        \n",
    "        videoSpacialEntities = getSpacialEntities_google(videoContext,MyAPIsuffix[index])\n",
    "        \n",
    "        #videoSpacialEntities = getSpacialEntities_nvidia(videoContext)\n",
    "        \n",
    "        #print(\"videoSpacialEntities  \",videoSpacialEntities)\n",
    "        if len(videoSpacialEntities) > 0:\n",
    "            output = []\n",
    "            for ent in videoSpacialEntities:\n",
    "                geocoding = getGeocoding(ent)\n",
    "                if geocoding :\n",
    "                    geocoding['ent']=ent\n",
    "                    output.append(geocoding)\n",
    "            if len(output) >0 :\n",
    "                video['output'] = output\n",
    "                \n",
    "        # Updating the new list\n",
    "        updatedVideos.append(video)\n",
    "        \n",
    "        # Safe Saving \n",
    "        counter+= 1\n",
    "        if counter == 100:\n",
    "            saveJson(\"./jsons/updatedVideos.json\",updatedVideos)\n",
    "            counter =0\n",
    "            \n",
    "        # API Switching\n",
    "        \n",
    "        apiCounter +=1\n",
    "        if apiCounter == 13:\n",
    "            index+=1\n",
    "            apiCounter = 0\n",
    "            if index==5:\n",
    "                print(Style.BRIGHT+Fore.BLUE+'\\n sleep for 60s'+Style.RESET_ALL)\n",
    "                time.sleep(60)\n",
    "                index=0\n",
    "            print(Style.BRIGHT+Fore.YELLOW+f'\\n API KEY switched to {MyAPIsuffix[index]}'+Style.RESET_ALL)\n",
    "            \n",
    "        \"\"\"\n",
    "        apiCounter +=1\n",
    "        if apiCounter == 35:\n",
    "            print(Style.BRIGHT+Fore.BLUE+'\\n sleep for 60s'+Style.RESET_ALL)\n",
    "            time.sleep(60)\n",
    "            apiCounter = 0\n",
    "        \"\"\"\n",
    "        \n",
    "    # Saving \n",
    "    saveJson(\"./jsons/updatedVideos.json\",updatedVideos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb943e",
   "metadata": {},
   "source": [
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1382096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Ils vivent dans une maison bâtie avec des déchets\"\n",
    "description = \"\\\"Elle nous protège, elle nous nourrit, elle nous réchauffe, elle nous offre tous nos besoins primaires.\\\"\\n\\nPendant ce temps-là à Biras, en Dordogne, Pauline, Benjamin et Noéha vivent dans cette maison enterrée, autonome en énergie et bâtie avec des déchets. Visite de leur earthship.\\n\\n————————————— \\n▶︎ Retrouvez la vidéo sur le site de Brut https://www.brut.media/fr/science-and-technology/ils-vivent-dans-une-maison-batie-avec-des-dechets-cebe8641-ba94-4e76-843a-10b58e4a35fa\\n▶ 📲 sur l’appli Brut (iOS) : https://apple.co/2UY7gNH \\n▶ 📲 sur l’appli Brut (Android) : https://play.google.com/store/apps/details?id=media.brut.brut \\n👉 Abonnez-vous à la newsletter myBrut : https://bit.ly/2JhQ5pP\\n▶ Pour ne rien louper des vidéos Brut, n’hésitez pas à vous abonner ➞ https://www.youtube.com/channel/UCSKdvgqdnj72_SLggp7BDTg/?sub_confirmation=1 et à activer la cloche 🔔\"\n",
    "tags =  [\n",
    "      \"brut\",\n",
    "      \"déchet\",\n",
    "      \"maison\",\n",
    "      \"construction\",\n",
    "      \"poubelle\",\n",
    "      \"verre\",\n",
    "      \"recyclage\"\n",
    "    ]\n",
    "\n",
    "videoTestContexte = getContext(title, description, tags)\n",
    "\n",
    "#print(videoTestContexte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5e4cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de texte avec des noms de lieux\n",
    "texte_contenu = \"\"\"\n",
    "Lors de mon voyage en Provence, j’ai visité Marseille, le quartier du Panier, Aix-en-Provence \n",
    "et un petit village appelé Eygalières. Ensuite, nous sommes allés à Nice et dans le Vieux-Nice.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e70bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "getSpacialEntities_google(videoTestContexte,'MONO_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "getLLMresponse_ollama(texte_contenu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18695822",
   "metadata": {},
   "outputs": [],
   "source": [
    "getSpacialEntities_nvidia(videoTestContexte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0fe31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "getEntityVerification('biras','./csvs/v_commune_2025.csv','NCCENR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e28bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "getGeocoding('provence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d9dfe",
   "metadata": {},
   "source": [
    "- Run on All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7aa2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "runAll(\"./jsons/videosForSpacialAnalysis.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fef657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90b7747e",
   "metadata": {},
   "source": [
    "## Videos of non pertinents channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccabfc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedVideos = openJson(\"./jsons/updatedVideos.json\")\n",
    "len(updatedVideos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(\n",
    "    dbname=\"youtubestay\",\n",
    "    user=\"postgres\",\n",
    "    password=os.getenv(\"POSTGRE_PASSWORD\"),\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT v.id_video\n",
    "    FROM videos v join chaines c\n",
    "    ON v.id_chaine = c.id_chaine\n",
    "    WHERE c.pertinente= false ;\n",
    "\"\"\")\n",
    "\n",
    "rows = cur.fetchall()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "ids = [row[0] for row in rows]\n",
    "cleaned = []\n",
    "len(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c8402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in updatedVideos:\n",
    "    if video['id_video'] not in ids:\n",
    "            cleaned.append(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652c8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveJson(\"./jsons/updatedVideos.json\",cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e11f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "videosForSpacialAnalysis = openJson(\"./jsons/updatedVideos.json\")\n",
    "len(updatedVideos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6105a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9386ca47",
   "metadata": {},
   "source": [
    "### Plot coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "location_data = {\n",
    "        \"lat\": 49.5532646,\n",
    "        \"lon\": 2.9392577,\n",
    "        \"ent\": \"ville\"\n",
    "      }\n",
    "\n",
    "map_obj = folium.Map(location=[location_data[\"lat\"], location_data[\"lon\"]], zoom_start=13)\n",
    "\n",
    "folium.Marker(\n",
    "    [location_data[\"lat\"], location_data[\"lon\"]],\n",
    "    popup=location_data[\"ent\"],\n",
    "    tooltip=location_data[\"ent\"]\n",
    ").add_to(map_obj)\n",
    "\n",
    "map_obj.save(\"map_janze.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f750c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agrotube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
